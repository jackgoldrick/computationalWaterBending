\documentclass{article}
\usepackage{amsmath, amsthm, amsfonts, amssymb}
\usepackage{tikz-cd}
\usepackage{geometry}
\geometry{margin=1in}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem{example}{Example}
\title{Categorical Framework for Dimensional Analysis and System Classification}
\author{}
\date{}

\begin{document}
	
	\maketitle
	
	\begin{abstract}
		This paper develops a categorical framework to formalize dimensional analysis using display categories, functors, natural transformations, and universal properties. By introducing isometric and isomorphic invariances of dimensionless groups, we establish a method to classify physical systems into equivalence classes based on their behaviors. This framework unifies different physical domains and provides a systematic approach to analyze and predict system behaviors across various fields, including applications to machine learning models. We also explore the implications of linear dependence in dimension vector spaces on overfitting in modeling, discuss how the Buckingham Pi theorem fits into this framework as a special case involving free object generators, investigate the role of universal properties in dimensional analysis, and extend the framework to account for chaos, randomness, and bifurcations in dynamical systems through differential equations, transfer functions, and transforms.
	\end{abstract}
	
	\tableofcontents
	
	\section{Introduction}
	
	Dimensional analysis is a fundamental tool in physics and engineering, providing insight into the relationships between physical quantities and allowing for the formation of dimensionless groups that characterize system behaviors. In this paper, we extend the traditional approach by applying category theory to dimensional analysis, introducing \emph{display categories}, functors, natural transformations, and universal properties to create a formal framework for classifying and comparing physical systems. We further explore applications of this framework in machine learning models, discuss how linear dependence in dimension vector spaces relates to overfitting in modeling, examine how the Buckingham Pi theorem operates within this categorical context, investigate the role of universal objects and properties, and extend the framework to account for chaos, randomness, and bifurcations in dynamical systems using differential equations, transfer functions, and Fourier/Laplace transforms.
	
	\section{Preliminaries}
	
	\subsection{Basic Definitions in Category Theory}
	
	\begin{definition}[Category]
		A \emph{category} $\mathcal{C}$ consists of:
		\begin{itemize}
			\item A class of \emph{objects} $\operatorname{Ob}(\mathcal{C})$.
			\item For every pair of objects $A, B \in \operatorname{Ob}(\mathcal{C})$, a set of \emph{morphisms} (or arrows) $\operatorname{Hom}_{\mathcal{C}}(A, B)$.
			\item For every triple of objects $A, B, C \in \operatorname{Ob}(\mathcal{C})$, a composition law $\circ: \operatorname{Hom}_{\mathcal{C}}(B, C) \times \operatorname{Hom}_{\mathcal{C}}(A, B) \rightarrow \operatorname{Hom}_{\mathcal{C}}(A, C)$.
			\item For every object $A \in \operatorname{Ob}(\mathcal{C})$, an identity morphism $\operatorname{id}_A \in \operatorname{Hom}_{\mathcal{C}}(A, A)$.
		\end{itemize}
		These must satisfy the associativity and identity axioms.
	\end{definition}
	
	\begin{definition}[Functor]
		A \emph{functor} $F: \mathcal{C} \rightarrow \mathcal{D}$ between categories $\mathcal{C}$ and $\mathcal{D}$ is a mapping that:
		\begin{itemize}
			\item Assigns to each object $A \in \operatorname{Ob}(\mathcal{C})$ an object $F(A) \in \operatorname{Ob}(\mathcal{D})$.
			\item Assigns to each morphism $f: A \rightarrow B$ in $\mathcal{C}$ a morphism $F(f): F(A) \rightarrow F(B)$ in $\mathcal{D}$.
		\end{itemize}
		Such that:
		\begin{itemize}
			\item $F(\operatorname{id}_A) = \operatorname{id}_{F(A)}$ for all $A \in \operatorname{Ob}(\mathcal{C})$.
			\item $F(g \circ f) = F(g) \circ F(f)$ for all composable morphisms $f, g$ in $\mathcal{C}$.
		\end{itemize}
	\end{definition}
	
	\begin{definition}[Natural Transformations]
		Given two functors $F, G: \mathcal{C} \rightarrow \mathcal{D}$, a \emph{natural transformation} $\eta: F \Rightarrow G$ assigns to each object $A \in \operatorname{Ob}(\mathcal{C})$ a morphism $\eta_A: F(A) \rightarrow G(A)$ in $\mathcal{D}$, such that for every morphism $f: A \rightarrow B$ in $\mathcal{C}$, the following diagram commutes:
		\[
		\begin{tikzcd}
			F(A) \arrow[r, "F(f)"] \arrow[d, "\eta_A"'] & F(B) \arrow[d, "\eta_B"] \\
			G(A) \arrow[r, "G(f)"'] & G(B)
		\end{tikzcd}
		\]
	\end{definition}
	
	\subsection{Dimensional Analysis and Dimensionless Groups}
	
	\begin{definition}[Dimension]
		A \emph{dimension} is a fundamental measure of a physical quantity, represented symbolically (e.g., mass $[M]$, length $[L]$, time $[T]$).
		
		A \emph{dimensioned quantity} is a physical variable associated with a combination of dimensions, expressed as $[M]^a[L]^b[T]^c$, where $a, b, c \in \mathbb{R}$.
	\end{definition}
	
	\begin{definition}[Dimensionless]
		A \emph{dimensionless group} is a combination of physical variables and constants that results in a quantity without units, i.e., all dimensions cancel out.
	\end{definition}
	
	\subsection{Dimension Vector Spaces}
	
	\begin{definition}[Dimensioned Vector Space]
		The \emph{dimensioned vector space} $\mathcal{V}_D$ is a real vector space formed by the exponents of the fundamental dimensions. Each dimensioned quantity corresponds to a vector in $\mathcal{V}_D$.
	\end{definition}
	
	\section{Display Categories and Dimensional Systems}
	
	\subsection{Display Categories}
	
	\begin{definition}[Display Category]
		A \emph{display category} $\mathcal{V}$ over a base category $\mathcal{D}$ is a category where:
		\begin{itemize}
			\item Objects of $\mathcal{V}$ are variables associated with dimensions in $\mathcal{D}$.
			\item Morphisms in $\mathcal{V}$ represent relationships (e.g., equations, transformations) between these variables.
			\item There is a functor $p: \mathcal{V} \rightarrow \mathcal{D}$ called the \emph{display functor}, which maps each variable to its associated dimension.
		\end{itemize}
	\end{definition}
	
	\subsection{Base Category of Dimensions}
	
	Let $\mathcal{D}$ be the base category where:
	\begin{itemize}
		\item $\operatorname{Ob}(\mathcal{D})$ consists of fundamental dimensions $[M], [L], [T], \dots$.
		\item Morphisms in $\mathcal{D}$ represent dimension transformations (e.g., scaling, combination).
	\end{itemize}
	
	\subsection{Variables and Morphisms}
	
	In the display category $\mathcal{V}$:
	\begin{itemize}
		\item Objects are physical variables (e.g., mass $m$, velocity $v$, force $F$) with associated dimensions via the functor $p$.
		\item Morphisms represent physical laws or relationships between variables (e.g., $F = m a$, $v = \dfrac{dx}{dt}$).
	\end{itemize}
	
	\section{Functors and Natural Transformations in Dimensional Systems}
	
	\subsection{Unit Systems as Functors}
	
	Let $\mathcal{U}_{\text{SI}}$ and $\mathcal{U}_{\text{Imperial}}$ be categories representing the SI and Imperial unit systems, respectively.
	
	Define functors:
	\begin{align*}
		F_{\text{SI}} &: \mathcal{D} \rightarrow \mathcal{U}_{\text{SI}}, \\
		F_{\text{Imperial}} &: \mathcal{D} \rightarrow \mathcal{U}_{\text{Imperial}}.
	\end{align*}
	
	These functors map dimensions to units in each system.
	
	\subsection{Natural Transformations as Unit Conversions}
	
	\begin{definition}[Natural Conversions]
		A natural transformation $\eta: F_{\text{SI}} \Rightarrow F_{\text{Imperial}}$ represents unit conversions between the SI and Imperial systems.
		
		For each dimension $[D] \in \operatorname{Ob}(\mathcal{D})$, $\eta_{[D]}: F_{\text{SI}}([D]) \rightarrow F_{\text{Imperial}}([D])$ is the conversion factor between units.
	\end{definition}
	
	\subsection{Invariance of Dimensionless Groups}
	
	\begin{theorem}[Dimensionless Invariance Theorem]
		Let $\Pi$ be a dimensionless group formed from variables in $\mathcal{V}$ associated with dimensions in $\mathcal{D}$. Then, under the natural transformation $\eta: F_{\text{SI}} \Rightarrow F_{\text{Imperial}}$, $\Pi$ remains invariant.
		
		\begin{proof}
			Since $\Pi$ is dimensionless, it is constructed such that all dimensional units cancel out. Under the natural transformation $\eta$, each variable transforms according to unit conversion factors, but the ratios and products in $\Pi$ ensure that these factors cancel. Therefore, $\Pi$ is invariant under $\eta$.
		\end{proof}
	\end{theorem}
	
	\section{Isometric and Isomorphic Invariances}
	
	\subsection{Isometric Invariance}
	
	\begin{definition}[Isometric Transformations]
		An \emph{isometric transformation} in this context is a mapping between two systems that preserves quantitative relationships, such as ratios or magnitudes of variables.
		
		Formally, consider two systems $S_1$ and $S_2$ with variable sets $\{v_i\}$ and $\{v'_i\}$, respectively. An isometric transformation $\phi: S_1 \rightarrow S_2$ satisfies:
		\[
		\phi(v_i) = k v_i,
		\]
		where $k$ is a constant scaling factor, and the relationships between variables in $S_1$ are preserved in $S_2$.
		
		Two systems are \emph{isometrically invariant} if there exists an isometric transformation between them that preserves these quantitative relationships.
	\end{definition}
	
	\begin{theorem}[Isometric Invariance Principle]
		If two systems $S_1$ and $S_2$ are related by an isometric transformation $\phi$, then any dimensionless groups formed from variables in $S_1$ are invariant under $\phi$.
		
	\begin{proof}
		Let $\Pi$ be a dimensionless group formed from variables in $S_1$:
		\[
		\Pi = \prod_{i=1}^n v_i^{\alpha_i},
		\]
		where $v_i$ are physical variables, $\alpha_i \in \mathbb{R}$, and $\Pi$ is dimensionless.
		
		Each variable $v_i$ has dimensions expressed in terms of the fundamental dimensions $[D_k]$:
		\[
		[v_i] = \prod_{k=1}^m [D_k]^{d_{ik}},
		\]
		where $d_{ik} \in \mathbb{R}$ are the dimension exponents for each fundamental dimension $[D_k]$.
		
		Because $\Pi$ is dimensionless, the combined exponents of each fundamental dimension must sum to zero:
		\[
		\sum_{i=1}^n \alpha_i d_{ik} = 0 \quad \text{for each fundamental dimension } [D_k].
		\]
		
		Now, consider an isometric transformation $\phi$ that scales the units of the fundamental dimensions by constant factors $k_k > 0$:
		\[
		[D_k] \mapsto \phi([D_k]) = k_k [D_k].
		\]
		
		Under this transformation, the units of each variable $v_i$ transform as:
		\[
		[v_i] \mapsto \phi([v_i]) = \prod_{k=1}^m (k_k [D_k])^{d_{ik}} = \left( \prod_{k=1}^m k_k^{d_{ik}} \right) [v_i].
		\]
		
		Therefore, each variable $v_i$ scales as:
		\[
		v_i \mapsto \phi(v_i) = \left( \prod_{k=1}^m k_k^{d_{ik}} \right) v_i = K_i v_i,
		\]
		where $K_i = \prod_{k=1}^m k_k^{d_{ik}}$.
		
		Applying the transformation to $\Pi$:
		\[
		\phi(\Pi) = \prod_{i=1}^n \left( \phi(v_i) \right)^{\alpha_i} = \prod_{i=1}^n \left( K_i v_i \right)^{\alpha_i} = \left( \prod_{i=1}^n K_i^{\alpha_i} \right) \left( \prod_{i=1}^n v_i^{\alpha_i} \right) = \left( \prod_{i=1}^n K_i^{\alpha_i} \right) \Pi.
		\]
		
		Compute the product of the scaling factors:
		\begin{align*}
			\prod_{i=1}^n K_i^{\alpha_i} &= \prod_{i=1}^n \left( \prod_{k=1}^m k_k^{d_{ik}} \right)^{\alpha_i} = \prod_{i=1}^n \prod_{k=1}^m k_k^{\alpha_i d_{ik}} = \prod_{k=1}^m \prod_{i=1}^n k_k^{\alpha_i d_{ik}} \\
			&= \prod_{k=1}^m k_k^{\sum_{i=1}^n \alpha_i d_{ik}}.
		\end{align*}
		
		Since $\sum_{i=1}^n \alpha_i d_{ik} = 0$ for each $k$, we have:
		\[
		\prod_{k=1}^m k_k^{\sum_{i=1}^n \alpha_i d_{ik}} = \prod_{k=1}^m k_k^{0} = 1.
		\]
		
		Therefore,
		\[
		\phi(\Pi) = 1 \times \Pi = \Pi.
		\]
		
		Thus, the dimensionless group $\Pi$ remains invariant under the isometric transformation $\phi$.
	\end{proof}
	\end{theorem}
	
	\subsection{Isomorphic Invariance}
	
	\begin{definition}[Isomorphism]
		An \emph{isomorphism} between two categories $\mathcal{C}$ and $\mathcal{D}$ is a functor $F: \mathcal{C} \rightarrow \mathcal{D}$ that is invertible, i.e., there exists a functor $G: \mathcal{D} \rightarrow \mathcal{C}$ such that $G \circ F = \operatorname{id}_{\mathcal{C}}$ and $F \circ G = \operatorname{id}_{\mathcal{D}}$.
		
		Two systems are \emph{isomorphically invariant} if their categories are isomorphic, preserving the structural relationships between variables and equations.
	\end{definition}
	
	\begin{theorem}[Isomorphic Preservation Theorem]
		If two systems $S_1$ and $S_2$ have categories $\mathcal{C}_1$ and $\mathcal{C}_2$ that are isomorphic via a functor $F: \mathcal{C}_1 \rightarrow \mathcal{C}_2$, then the structural relationships (morphisms) in $S_1$ are preserved in $S_2$.
		
		\begin{proof}
			Since $F$ is an isomorphism, it maps objects and morphisms in $\mathcal{C}_1$ to objects and morphisms in $\mathcal{C}_2$ such that the categorical structure is preserved.
			
			For any objects $A$, $B$ in $\mathcal{C}_1$, and any morphism $f: A \rightarrow B$, $F(f): F(A) \rightarrow F(B)$ in $\mathcal{C}_2$.
			
			Because $G \circ F = \operatorname{id}_{\mathcal{C}_1}$ and $F \circ G = \operatorname{id}_{\mathcal{C}_2}$, $F$ is invertible, ensuring that the structural relationships are fully preserved.
			
			Therefore, the equations and relationships in $S_1$ are mapped to equivalent equations and relationships in $S_2$, preserving the system's structure.
		\end{proof}
	\end{theorem}
	
	\section{Equivalence Classes via Dimensionless Groups}
	
	\subsection{Classification of Systems}
	
	\begin{definition}[Equivalence Class]
		An \emph{equivalence class} of systems is a set of systems that share the same dimensionless groups and exhibit similar behaviors under corresponding conditions.
		
		We denote an equivalence class $\mathcal{E}_\Pi$ for systems sharing a dimensionless group $\Pi$.
	\end{definition}
	
	\subsection{Formation of Equivalence Classes}
	
	\begin{theorem}[Golden Equivalence Classification Theorem]
		Systems that are isometrically or isomorphically invariant under transformations preserving their dimensionless groups belong to the same equivalence class $\mathcal{E}_\Pi$.
		
		\begin{proof}
			Let systems $S_1$ and $S_2$ have categories $\mathcal{C}_1$ and $\mathcal{C}_2$, respectively, with associated dimensionless groups $\Pi_1$ and $\Pi_2$.
			
			Suppose there exists:
			\begin{itemize}
				\item An isometric transformation $\phi: S_1 \rightarrow S_2$ preserving quantitative relationships.
				\item An isomorphism $F: \mathcal{C}_1 \rightarrow \mathcal{C}_2$ preserving structural relationships.
			\end{itemize}
			
			Since $\phi$ and $F$ preserve the dimensionless groups (i.e., $\Pi_1 = \Pi_2$), and the systems exhibit similar behaviors under these transformations, they belong to the same equivalence class $\mathcal{E}_\Pi$.
		\end{proof}
	\end{theorem}
	
	\subsection{Examples of Equivalence Classes}
	
	\subsubsection{Reynolds Number in Fluid Dynamics}
	
	\begin{definition}[Reynolds Number]
		The \emph{Reynolds number} $\operatorname{Re}$ is a dimensionless group defined as:
		\[
		\operatorname{Re} = \dfrac{\rho v L}{\mu},
		\]
		where:
		\begin{itemize}
			\item $\rho$ is the fluid density ($[M][L]^{-3}$).
			\item $v$ is the fluid velocity ($[L][T]^{-1}$).
			\item $L$ is a characteristic length ($[L]$).
			\item $\mu$ is the dynamic viscosity ($[M][L]^{-1}[T]^{-1}$).
		\end{itemize}
	\end{definition}
	
	\begin{theorem}[Reynolds Equivalence Theorem]
		Fluid systems with the same Reynolds number $\operatorname{Re}$ exhibit similar flow characteristics and belong to the same equivalence class $\mathcal{E}_{\operatorname{Re}}$.
		
		\begin{proof}
			The Reynolds number $\operatorname{Re}$ encapsulates the ratio of inertial forces to viscous forces in a fluid flow. Systems with the same $\operatorname{Re}$ have proportional relationships between these forces, leading to similar flow patterns (e.g., laminar or turbulent flow).
			
			Through an isometric transformation preserving the Reynolds number, variables in one system can be scaled to those in another while maintaining the quantitative relationships. Therefore, these systems exhibit similar behaviors and belong to the same equivalence class $\mathcal{E}_{\operatorname{Re}}$.
		\end{proof}
	\end{theorem}
	
	\subsubsection{Electrical-Mechanical System Analogy}
	
	\begin{definition}
		Consider the mechanical system governed by:
		\[
		F(t) = m \ddot{x}(t) + c \dot{x}(t) + k x(t),
		\]
		and the electrical circuit governed by:
		\[
		V(t) = L \ddot{Q}(t) + R \dot{Q}(t) + \dfrac{1}{C} Q(t).
		\]
	\end{definition}
	
	\begin{theorem}[Shalom's System Analog Theorem]
		The mechanical and electrical systems are isomorphically invariant under a functorial mapping that preserves the structural form of their governing equations.  The resulting systems are equivalent over their dimensionless groups analogs.
		
		\begin{proof}
			Define a functor $F: \mathcal{C}_{\text{mech}} \rightarrow \mathcal{C}_{\text{elec}}$ such that:
			\begin{align*}
				F(x(t)) &= Q(t), \\
				F(\dot{x}(t)) &= \dot{Q}(t), \\
				F(\ddot{x}(t)) &= \ddot{Q}(t), \\
				F(F(t)) &= V(t), \\
				F(m) &= L, \\
				F(c) &= R, \\
				F(k) &= \dfrac{1}{C}.
			\end{align*}
			
			The morphisms (differential relationships) are preserved under $F$:
			\[
			F\left( m \ddot{x}(t) + c \dot{x}(t) + k x(t) \right) = L \ddot{Q}(t) + R \dot{Q}(t) + \dfrac{1}{C} Q(t).
			\]
			
			Since $F$ is invertible (with inverse mapping electrical quantities back to mechanical ones), and it preserves the structural relationships, the two systems are isomorphic. Therefore, they are isomorphically invariant and can be classified into the same equivalence class based on their dimensionless group analogs.
		\end{proof}
	\end{theorem}
	
	\section{Extension to Dynamical Systems}
	
	\subsection{Differential Equations as Morphisms}
	
	\begin{definition}[Dynamical Displays]
		In dynamical systems, the evolution of variables over time can be represented as morphisms in the display category.
		
		Let $\mathcal{V}$ be a display category where:
		\begin{itemize}
			\item Objects are state variables $x(t)$, $v(t)$, $a(t)$.
			\item Morphisms are differential equations relating these variables, e.g., $v(t) = \dfrac{dx(t)}{dt}$.
		\end{itemize}
	\end{definition}
	
	\subsection{Transfer Functions and Laplace Transforms}
	
	\begin{definition}[Transfer Function Transformation]
		A \emph{transfer function} $H(s)$ in control theory and signal processing is a complex function representing the relationship between the input and output of a linear time-invariant (LTI) system in the Laplace domain:
		\[
		H(s) = \dfrac{\mathcal{L}\{ \text{Output}(t) \}}{\mathcal{L}\{ \text{Input}(t) \}},
		\]
		where $\mathcal{L}\{ \cdot \}$ denotes the Laplace transform, and $s$ is the complex frequency parameter.
	\end{definition}
	
	\begin{proposition}[Laplace Transform as Functor]
		The Laplace transform can be viewed as a functor $\mathcal{L}: \mathcal{V}_{\text{time}} \rightarrow \mathcal{V}_{\text{Laplace}}$, mapping time-domain functions to Laplace-domain functions.
		
		\begin{proof}
			In the categorical framework:
			\begin{itemize}
				\item Objects in $\mathcal{V}_{\text{time}}$ are time-domain signals (functions of $t$).
				\item Objects in $\mathcal{V}_{\text{Laplace}}$ are Laplace-domain representations (functions of $s$).
				\item Morphisms in $\mathcal{V}_{\text{time}}$ represent differential equations or convolution operations.
				\item Morphisms in $\mathcal{V}_{\text{Laplace}}$ represent algebraic equations.
			\end{itemize}
			
			The Laplace transform functor $\mathcal{L}$ maps differential equations in the time domain to algebraic equations in the Laplace domain, preserving the structure of the relationships. This mapping satisfies the functorial properties of preserving composition and identities.
		\end{proof}
	\end{proposition}
	
	\subsection{Fourier Transforms and Frequency Domain Analysis}
	
	\begin{definition}[Fourier Functor]
		The \emph{Fourier transform} is an integral transform that decomposes a time-domain signal into its constituent frequencies:
		\[
		\mathcal{F}\{ f(t) \} = F(\omega) = \int_{-\infty}^{\infty} f(t) e^{-i \omega t} dt.
		\]
		
		It can be viewed as a functor $\mathcal{F}: \mathcal{V}_{\text{time}} \rightarrow \mathcal{V}_{\text{frequency}}$.
		
	\end{definition}
	
	\begin{proposition}[Frequency Domain Morphisms]
		In the frequency domain, convolution in time corresponds to multiplication in frequency. Morphisms representing convolutions in $\mathcal{V}_{\text{time}}$ are mapped to morphisms representing multiplications in $\mathcal{V}_{\text{frequency}}$.
		
		\begin{proof}
			The Fourier transform of a convolution is the product of the Fourier transforms:
			\[
			\mathcal{F}\{ f(t) * g(t) \} = \mathcal{F}\{ f(t) \} \cdot \mathcal{F}\{ g(t) \}.
			\]
			
			Therefore, the Fourier functor $\mathcal{F}$ maps convolution morphisms in the time domain to multiplication morphisms in the frequency domain, preserving the compositional structure.
		\end{proof}
	\end{proposition}
	
	\subsection{Bifurcations in Dynamical Systems}
	
	\begin{definition}[Bifurcation Basics]
		A \emph{bifurcation} occurs when a small smooth change made to the parameter values of a system causes a sudden qualitative or topological change in its behavior.
		
		In the context of dynamical systems, bifurcations can be represented as changes in the structure of the system's morphisms when parameters cross critical values.
	\end{definition}
	
	\begin{theorem}[Freyja's Bifurcation Transition Theorem]
		Bifurcations in a dynamical system can be modeled as transitions between functors representing different dynamical regimes in the display category.
		
		\begin{proof}
			Consider a family of dynamical systems parameterized by $\mu$, with corresponding categories $\mathcal{V}_\mu$:
			\[
			\frac{dx}{dt} = f(x, \mu).
			\]
			
			As the parameter $\mu$ varies, the system may undergo a bifurcation at a critical value $\mu_c$, changing the qualitative behavior of solutions.
			
			We can represent the system's dynamics as a functor $F_\mu: \mathcal{V} \rightarrow \mathcal{V}$, where the morphisms (flows) depend on $\mu$. At $\mu = \mu_c$, the functor undergoes a structural change, representing the bifurcation.
			
			This change can be formalized using a natural transformation $\eta: F_{\mu^-} \Rightarrow F_{\mu^+}$, where $\mu^-$ and $\mu^+$ are values just before and after $\mu_c$. The natural transformation captures the shift in the system's dynamics due to the bifurcation.
		\end{proof}
	\end{theorem}
	
	\begin{example}[Pitchfork Bifurcation]
		Consider the normal form of a pitchfork bifurcation:
		\[
		\frac{dx}{dt} = \mu x - x^3.
		\]
		
		\begin{itemize}
			\item For $\mu < 0$, the only equilibrium is at $x = 0$, which is stable.
			\item For $\mu > 0$, $x = 0$ becomes unstable, and two new stable equilibria emerge at $x = \pm \sqrt{\mu}$.
		\end{itemize}
		
		In the categorical framework, the morphisms change structure at $\mu = 0$, representing the bifurcation. The functors $F_{\mu<0}$ and $F_{\mu>0}$ map objects (states) to different sets of equilibria, and the transition at $\mu = 0$ is captured by a change in the functor's structure.
	\end{example}
	
	\subsection{Chaos and Randomness in Display Categories}
	
	\subsubsection{Representing Chaos in Dynamical Systems}
	
	\begin{definition}[Nonlinear Dynamics and Chaos]
		A \emph{chaotic system} is a deterministic dynamical system that exhibits sensitive dependence on initial conditions, meaning that small differences in initial states can lead to vastly different trajectories over time. This behavior is often due to nonlinearities in the governing equations.
	\end{definition}
	
	In the display category framework, we can represent chaotic systems by incorporating nonlinear morphisms that capture the system's dynamics.
	
	\begin{proposition}[Chaos Modeling Proposition]
		Let $\mathcal{V}$ be a display category where:
		\begin{itemize}
			\item Objects are states of the system at different times.
			\item Morphisms represent the evolution of the system over time, governed by nonlinear functions.
		\end{itemize}
		Then, the sensitive dependence on initial conditions characteristic of chaos can be modeled by the composition of these nonlinear morphisms.
	\end{proposition}
	
	\begin{proof}
		Consider a dynamical system defined by a nonlinear map or differential equation:
		\[
		x_{n+1} = f(x_n),
		\]
		or
		\[
		\frac{dx(t)}{dt} = f(x(t)),
		\]
		where $f$ is a nonlinear function. The morphisms in the category correspond to the application of $f$ over time.
		
		Due to the nonlinearity, small changes in $x_0$ can lead to significant differences in $x_n$ for large $n$, illustrating sensitive dependence on initial conditions.
		
		Thus, the sequence of morphisms $f, f \circ f, f \circ f \circ f, \dots$ captures the chaotic evolution of the system within the category.
	\end{proof}
	
	
	\subsubsection{Chaos as an Infinite Sequence of Morphisms}
	
	In this subsection, we formalize the concept of chaos within the categorical framework by interpreting chaotic dynamics as infinite sequences of morphisms that neither terminate at a terminal object nor repeat cyclically. This perspective complements the \emph{Chaos Modeling Proposition} and provides a deeper understanding of how chaotic behavior can be represented categorically.
	
	\paragraph{Definition: Infinite Sequence of Morphisms Representing Chaos}
	
	\begin{definition}[Chaotic Infinite Morphism Sequence]
		Let $\mathcal{C}$ be a category where the objects represent the states of a dynamical system, and morphisms represent state transitions over time. A \emph{chaotic infinite morphism sequence} is an infinite sequence of morphisms
		\[
		X_1 \xrightarrow{f_1} X_2 \xrightarrow{f_2} X_3 \xrightarrow{f_3} \cdots,
		\]
		such that:
		\begin{enumerate}
			\item The sequence does not terminate at a terminal object; there is no object $T$ in $\mathcal{C}$ such that $X_i \rightarrow T$ for all $i$.
			\item The sequence does not repeat cyclically; there are no indices $i < j$ such that $X_i \cong X_j$ and the subsequence from $X_i$ to $X_j$ forms a cycle.
			\item The morphisms $f_i$ are nonlinear and sensitive to initial conditions, capturing the essence of chaotic dynamics.
		\end{enumerate}
	\end{definition}
	
	\paragraph{Theorem: Representation of Chaos in the Categorical Framework}
	
	\begin{theorem}[Chaos as Non-Terminating, Aperiodic Morphism Sequences]
		In the categorical framework, chaotic dynamical systems can be represented by infinite sequences of morphisms that neither terminate at a terminal object nor repeat cyclically. Such sequences capture the sensitive dependence on initial conditions and aperiodic nature of chaotic systems.
		
		\begin{proof}
			Let $\mathcal{C}$ be a category where each object $X_i$ represents the state of the system at time $i$, and each morphism $f_i: X_i \rightarrow X_{i+1}$ represents the state transition from time $i$ to $i+1$.
			
			In chaotic systems, the following properties hold:
			
			\begin{enumerate}
				\item \textbf{No Terminal Object:} Chaotic systems do not converge to an equilibrium or steady state. Therefore, there is no terminal object $T$ such that there exists a unique morphism from any state $X_i$ to $T$.
				\item \textbf{Aperiodicity:} Chaotic systems do not exhibit periodic behavior over the long term. Thus, the states $X_i$ are all distinct up to isomorphism, and there are no cycles in the sequence of morphisms.
				\item \textbf{Sensitive Dependence on Initial Conditions:} The nonlinear morphisms $f_i$ amplify small differences in initial states, leading to divergent trajectories.
			\end{enumerate}
			
			By constructing an infinite sequence of morphisms as described, we capture these properties within the categorical framework. The absence of a terminal object and cycles reflects the non-convergent and aperiodic nature of chaos. The infinite composition of nonlinear morphisms models the complex evolution of the system over time.
			
			Therefore, chaotic dynamics are represented by infinite sequences of morphisms that neither terminate nor repeat cyclically in the category $\mathcal{C}$.
		\end{proof}
	\end{theorem}
	
	\paragraph{Example: The Logistic Map as a Chaotic System}
	
	Consider the logistic map, a well-known example of a system that can exhibit chaotic behavior:
	
	\[
	x_{n+1} = r x_n (1 - x_n),
	\]
	
	where $0 < x_n < 1$ and $r$ is a parameter typically in the range $3.57 < r \leq 4$ for chaos.
	
	\begin{itemize}
		\item \textbf{Objects:} Each state $X_n$ corresponds to the value $x_n$ at iteration $n$.
		\item \textbf{Morphisms:} The function $f: X_n \rightarrow X_{n+1}$ defined by $f(x) = r x (1 - x)$ represents the transition between states.
		\item \textbf{Infinite Sequence:} The trajectory of the system is represented by the infinite sequence $X_1 \xrightarrow{f} X_2 \xrightarrow{f} X_3 \xrightarrow{f} \cdots$.
	\end{itemize}
	
	In this system:
	
	\begin{enumerate}
		\item \textbf{No Terminal Object:} The system does not converge to a fixed point for chaotic values of $r$.
		\item \textbf{Aperiodicity:} The sequence of states does not repeat; the system exhibits aperiodic behavior.
		\item \textbf{Sensitive Dependence:} Small differences in the initial value $x_1$ lead to vastly different trajectories.
	\end{enumerate}
	
	Thus, the logistic map illustrates how a chaotic system can be modeled as an infinite sequence of morphisms without termination or cyclic repetition.
	
	\paragraph{Implications for the Categorical Framework}
	
	This interpretation of chaos has several implications:
	
	\begin{itemize}
		\item \textbf{Non-existence of Simplifying Universal Properties:} Unlike systems that converge to terminal objects or exhibit periodicity (allowing for simplifications via universal properties), chaotic systems resist such simplifications due to their complex behavior.
		\item \textbf{Infinite Complexity:} The infinite, non-repeating sequence of morphisms reflects the inherent complexity of chaotic systems.
		\item \textbf{Enhanced Modeling Capability:} By accommodating infinite sequences without termination or cycles, the categorical framework becomes robust enough to model a wider class of dynamical behaviors, including chaos.
	\end{itemize}
	
	\paragraph{Conclusion}
	
	By formalizing chaos as an infinite sequence of morphisms that neither terminates nor repeats cyclically, we extend the categorical framework to accurately represent chaotic dynamics. This approach aligns with the properties of chaotic systems and complements the \emph{Chaos Modeling Proposition}, providing a comprehensive tool for analyzing complex behaviors in dynamical systems.
	
	
	
	
	
	\subsubsection{Representing Randomness and Stochastic Processes}
	
	\begin{definition}[Stochastic Morphisms]
		A \emph{stochastic process} is a collection of random variables representing the evolution of a system under the influence of randomness.
		
		In the categorical framework, stochastic processes can be represented using morphisms that map between probability distributions or incorporate randomness into the mapping between objects.
	\end{definition}
	
	\begin{proposition}[Wanda's Stochastic Morphism Proposition]
		Let $\mathcal{V}$ be a display category where:
		\begin{itemize}
			\item Objects represent probability distributions over states.
			\item Morphisms represent stochastic transitions between these distributions.
		\end{itemize}
		Then, randomness in the dynamical system can be accounted for by these stochastic morphisms.
	\end{proposition}
	
	\begin{proof}
		Consider a stochastic differential equation (SDE) governing the system's evolution:
		\[
		dx(t) = \mu(x(t), t) dt + \sigma(x(t), t) dW(t),
		\]
		where $\mu$ is the drift term, $\sigma$ is the diffusion term, and $dW(t)$ represents a Wiener process (Brownian motion).
		
		In the category $\mathcal{V}$:
		\begin{itemize}
			\item Each object corresponds to the probability distribution of $x(t)$ at time $t$.
			\item Morphisms correspond to the transition kernels or operators that map the distribution at time $t$ to the distribution at time $t + dt$.
		\end{itemize}
		
		These morphisms incorporate the stochastic nature of the system through the diffusion term and the randomness of $dW(t)$.
		
		Therefore, the categorical framework can represent the evolution of probability distributions in stochastic systems via stochastic morphisms.
	\end{proof}
	
	\subsubsection{Implications for the Categorical Framework}
	
	By extending the display categories to include nonlinear and stochastic morphisms, we can account for chaos, randomness, and bifurcations in dynamical systems. This allows us to:
	
	\begin{itemize}
		\item Model chaotic dynamics through nonlinear morphisms, capturing sensitive dependence on initial conditions.
		\item Represent stochastic processes and randomness via morphisms that incorporate probabilistic transitions or stochastic differential equations.
		\item Describe bifurcations as structural changes in the functors or morphisms, representing qualitative changes in system behavior.
		\item Analyze complex systems within a unified categorical framework that accommodates both deterministic and stochastic behaviors, as well as structural transitions.
	\end{itemize}
	
	\section{Overfitting and Linear Dependence in Dimension Vector Spaces}
	
	\subsection{Linearly Dependent Units and Dimensional Redundancy}
	
	\begin{definition}[Dimension Dependence]
		In the dimension vector space $\mathcal{V}_D$, a set of dimension vectors $\{ \mathbf{d}_1, \mathbf{d}_2, \dots, \mathbf{d}_n \}$ is said to be \emph{linearly dependent} if there exist scalars $\alpha_1, \alpha_2, \dots, \alpha_n$, not all zero, such that:
		\[
		\alpha_1 \mathbf{d}_1 + \alpha_2 \mathbf{d}_2 + \dots + \alpha_n \mathbf{d}_n = \mathbf{0}.
		\]
	\end{definition}
	
	\begin{proposition}[Goldrick's Dimension Dependency Proposition]
		If a physical quantity's dimension vector is a linear combination of other dimension vectors, then the corresponding unit is \emph{dimensionally redundant} in modeling.
		
		\begin{proof}
			Let $\mathbf{d}_w$ be the dimension vector of a physical quantity $w$, and suppose it can be expressed as a linear combination of other dimension vectors:
			\[
			\mathbf{d}_w = \sum_{i=1}^{n} \beta_i \mathbf{d}_i,
			\]
			where $\beta_i \in \mathbb{R}$ and $\mathbf{d}_i$ are the dimension vectors of other physical quantities.
			
			This means that the dimensions of $w$ are determined entirely by the dimensions of the $\{ \mathbf{d}_i \}$. In modeling, including $w$ along with all the $\{ \mathbf{d}_i \}$ introduces redundancy because $w$ does not provide additional independent information beyond what is already captured by the $\{ \mathbf{d}_i \}$. Therefore, $w$ is dimensionally redundant in the context of the model.
		\end{proof}
	\end{proposition}
	
	\subsection{Example: Weight, Mass, and Acceleration}
	
	\begin{definition}
		Consider the relationship:
		\[
		w = m g,
		\]
		where:
		\begin{itemize}
			\item $w$ is the weight (force) of an object.
			\item $m$ is the mass of the object.
			\item $g$ is the acceleration due to gravity.
		\end{itemize}
	\end{definition}
	
	The dimension vectors are:
	\begin{align*}
		\mathbf{d}_w &= [M][L][T]^{-2} = (1,1,-2), \\
		\mathbf{d}_m &= [M] = (1,0,0), \\
		\mathbf{d}_g &= [L][T]^{-2} = (0,1,-2).
	\end{align*}
	
	We observe that:
	\[
	\mathbf{d}_w = \mathbf{d}_m + \mathbf{d}_g.
	\]
	
	This shows that the dimension vector of $w$ is a linear combination (specifically, the sum) of the dimension vectors of $m$ and $g$, indicating linear dependence.
	
	\subsection{Implications for Modeling and Overfitting}
	
	\begin{theorem}[Dimensional Overfitting Theorem]
		Including linearly dependent units in a model can lead to overfitting due to dimensional redundancy, analogous to multicollinearity in machine learning.
		
		\begin{proof}
			In modeling physical systems, the goal is to capture the essential relationships between independent variables and dependent variables. Including variables whose dimension vectors are linearly dependent introduces redundancy because these variables can be expressed in terms of other variables already present in the model.
			
			This redundancy increases the complexity of the model without providing new independent information. In statistical modeling, such as regression analysis, including linearly dependent (or highly collinear) predictors can inflate variance, make parameter estimates unstable, and reduce the model's ability to generalize to new data—hallmarks of overfitting.
			
			Similarly, in physical models, incorporating dimensionally redundant variables can cause the model to fit the specific dataset too closely, capturing noise rather than underlying physical laws. By analogy with multicollinearity, this overfitting reduces the model's predictive power and interpretability.
			
			Therefore, to prevent overfitting due to dimensional redundancy, it is important to identify and remove or combine linearly dependent units, simplifying the model while retaining its essential predictive capabilities.
		\end{proof}
	\end{theorem}
	
	\subsection{Avoiding Dimensional Overfitting in Models}
	
	\begin{proposition}[Freyr's Simplification Strategy Proposition]
		To prevent overfitting due to dimensional redundancy, models should be simplified by:
		\begin{itemize}
			\item Identifying and removing linearly dependent units.
			\item Using fundamental variables to represent the system.
			\item Employing dimensionless groups to reduce the number of variables.
		\end{itemize}
		
		\begin{proof}
			\begin{itemize}
				\item \textbf{Identifying and Removing Linearly Dependent Units:} By analyzing the dimension vectors of variables, we can detect linear dependencies. Removing redundant variables eliminates unnecessary complexity.
				
				\item \textbf{Using Fundamental Variables:} Focusing on a minimal set of independent variables ensures that the model captures the essential dynamics without overparameterization.
				
				\item \textbf{Employing Dimensionless Groups:} Dimensionless groups combine multiple variables into single entities that capture the relative effects of different physical quantities. This reduces the dimensionality of the problem and mitigates the risk of overfitting.
			\end{itemize}
			
			By applying these strategies, we simplify the model, enhance its generalizability, and maintain interpretability. This approach aligns with the principles of parsimonious modeling and dimensional analysis.
		\end{proof}
	\end{proposition}
	
	\subsection{Analogies with Machine Learning}
	
	\begin{definition}[Feature Finesse]
		In machine learning, \emph{multicollinearity} refers to the presence of features (variables) that are highly correlated or linearly dependent, which can adversely affect model training and interpretation.
	\end{definition}
	
	\begin{corollary}[Modeling Multicollinearity Corollary]
		The presence of linearly dependent dimension vectors in physical modeling is analogous to multicollinearity in machine learning models.
		
		\begin{proof}
			In both physical modeling and machine learning:
			\begin{itemize}
				\item \textbf{Redundancy:} Linearly dependent variables do not provide additional independent information, leading to redundancy.
				\item \textbf{Overfitting Risk:} Redundancy increases model complexity without enhancing predictive power, increasing the risk of overfitting.
				\item \textbf{Parameter Instability:} In statistical models, multicollinearity can cause large variances in parameter estimates. Similarly, in physical models, redundant variables can obscure the true relationships between variables.
			\end{itemize}
			
			Recognizing this analogy allows us to apply strategies from machine learning to physical modeling, such as variable selection, regularization, and dimensionality reduction, to mitigate overfitting due to redundancy.
		\end{proof}
	\end{corollary}
	
	
\section{Algorithmic Generation of Nonlinear Dimensionless Functions in Machine Learning}

\subsection{Introduction to the Algorithm}

In this section, we introduce an algorithm that extends the application of dimensionless groups (Pi groups) within machine learning models, specifically logistic regression. The algorithm generates nonlinear candidate functions by transforming and combining Pi groups, enabling the modeling of complex relationships between variables while maintaining dimensional consistency.

\subsection{Components of the Algorithm}

\subsubsection{The Pi Matrix {Phi}}

Let $\Phi$ be a matrix whose columns represent the exponents of the base variables that constitute the dimensionless Pi groups. Each column $\boldsymbol{\pi}_i$ corresponds to a Pi group, and the entries in the column are the exponents $a_{ji}$ such that:

\[
\Pi_i = \prod_{j=1}^{n} v_j^{a_{ji}},
\]

where $v_j$ are the base variables with dimensions, and $a_{ji} \in \mathbb{R}$ are the exponents that make $\Pi_i$ dimensionless.

\subsubsection{Transformation Functions {f} and {g}}

The functions $f$ and $g$ are designed to transform the Pi matrix $\Phi$ to create new combinations of Pi groups:

\begin{itemize}
	\item \textbf{Permutation Function $f$:} Rearranges the columns of $\Phi$, effectively permuting the Pi groups.
	\item \textbf{Combination Function $g$:} Applies operations such as multiplication or exponentiation of Pi groups to form new ones. For instance, combining $\Pi_1$ and $\Pi_2$ to form $\Pi_1 \times \Pi_2$ or $\Pi_1^\alpha \times \Pi_2^\beta$.
\end{itemize}

\subsubsection{Nonlinear Candidate Library: $\Phi_{\text{nl}}$}

The nonlinear transformation is defined as:

\[
\Phi_{\text{nl}} = \mathbf{v} \otimes \left( f(\Phi) + g(\Phi) \right),
\]

where:

\begin{itemize}
	\item $\mathbf{v}$ is a vector that scales or weights the transformed Pi groups.
	\item $\otimes$ denotes the Kronecker product (tensor product), which combines the vector $\mathbf{v}$ with the transformed Pi matrix to generate higher-order terms.
\end{itemize}

This transformation exploits scalar multiplication as raising to a power, enabling the creation of nonlinear combinations of the Pi groups.

\subsection{Integration into the Categorical Framework}

\subsubsection{Objects and Morphisms}

\begin{itemize}
	\item \textbf{Objects:} The Pi groups and their nonlinear combinations are objects in a category $\mathcal{P}$ of dimensionless quantities.
	\item \textbf{Morphisms:} The functions $f$ and $g$ act as morphisms in $\mathcal{P}$, transforming Pi groups into new Pi groups or combinations thereof.
\end{itemize}

\subsubsection{Functors Between Categories}

We define the following functors:

\begin{itemize}
	\item \textbf{Functor $F: \mathcal{V} \rightarrow \mathcal{P}$:} Maps dimensioned variables in $\mathcal{V}$ to Pi groups in $\mathcal{P}$.
	\item \textbf{Functor $G: \mathcal{P} \rightarrow \mathcal{F}$:} Maps Pi groups to nonlinear candidate functions in a category $\mathcal{F}$ of functions suitable for machine learning models.
\end{itemize}

The composition $G \circ F$ provides a mapping from the original variables to nonlinear functions, integrating the algorithm into the categorical framework.

\subsubsection{Tensor Products and Monoidal Categories}

The Kronecker product used in the algorithm corresponds to the tensor product in the context of monoidal categories. The category $\mathcal{P}$ becomes a monoidal category where:

\begin{itemize}
	\item \textbf{Tensor Product:} The combination of Pi groups via the tensor product represents the monoidal operation.
	\item \textbf{Associativity and Identity:} The tensor product is associative and has an identity element (the unit Pi group $\Pi = 1$).
\end{itemize}

\subsection{Theoretical Foundations}

\subsubsection{Goldrick's Nonlinear Feature Generation Theorem}

\begin{theorem}[Goldrick's Nonlinear Feature Generation Theorem]
	In the categorical framework of dimensional analysis, the nonlinear candidate functions generated via tensor products and transformations of Pi groups form a valid and dimensionally consistent basis for machine learning models, preserving physical interpretability and enhancing predictive capabilities.
\end{theorem}

\begin{proof}
	To prove this theorem, we need to show that the nonlinear functions generated are:
	
	\begin{enumerate}
		\item \textbf{Dimensionally Consistent:} Since the Pi groups are dimensionless by construction, any combination or transformation of Pi groups remains dimensionless. The operations performed by $f$ and $g$, as well as the tensor product with $\mathbf{v}$, do not introduce dimensions.
		\item \textbf{Valid Basis Functions:} The nonlinear functions span a function space suitable for modeling complex relationships. The tensor product allows for higher-order terms, and the transformations generate a rich set of candidate functions.
		\item \textbf{Preserving Physical Interpretability:} Each candidate function corresponds to a physically meaningful combination of variables, maintaining the interpretability essential in scientific modeling.
	\end{enumerate}
	
	Therefore, the algorithm produces functions that are both mathematically valid and physically meaningful within the categorical framework.
\end{proof}

\subsubsection{Proposition on Functorial Mapping}

\begin{proposition}[Functorial Mapping of Pi Groups to Functions]
	The mapping from Pi groups to nonlinear candidate functions via the algorithm defines a functor $G: \mathcal{P} \rightarrow \mathcal{F}$ that preserves the structure of the category $\mathcal{P}$ within $\mathcal{F}$.
\end{proposition}

\begin{proof}
	The functor $G$ maps objects (Pi groups) in $\mathcal{P}$ to objects (functions) in $\mathcal{F}$ and morphisms (transformations) in $\mathcal{P}$ to morphisms (function transformations) in $\mathcal{F}$. The operations performed by $f$ and $g$ correspond to morphisms in $\mathcal{P}$ and are preserved under $G$. The tensor product operation aligns with the monoidal structure, ensuring that the functorial mapping is consistent with the categorical framework.
\end{proof}

\subsection{Application to Logistic Regression}

\subsubsection{Generation of Candidate Functions}

Using the algorithm, we generate a set of nonlinear candidate functions:

\[
\Phi_{\text{nl}} = \mathbf{v} \otimes \left( f(\Phi) + g(\Phi) \right),
\]

where each element of $\Phi_{\text{nl}}$ corresponds to a nonlinear combination of Pi groups. These functions can include interactions, polynomial terms, and other nonlinear relationships.

\subsubsection{Incorporation into Logistic Regression}

In logistic regression, the probability of an outcome is modeled as:

\[
P(Y = 1) = \dfrac{1}{1 + e^{- ( \beta_0 + \boldsymbol{\beta}^\intercal \mathbf{x} ) }},
\]

where $\mathbf{x}$ is the vector of predictor variables, $\boldsymbol{\beta}$ is the vector of coefficients, and $\beta_0$ is the intercept. By replacing $\mathbf{x}$ with the generated nonlinear functions $\Phi_{\text{nl}}$, we obtain:

\[
P(Y = 1) = \dfrac{1}{1 + e^{- ( \beta_0 + \boldsymbol{\beta}^\intercal \Phi_{\text{nl}} ) }}.
\]

This allows the model to capture complex, nonlinear relationships between the predictors and the outcome while maintaining dimensional consistency.

\subsubsection{Example}

Suppose we have two Pi groups:

\[
\Pi_1 = \dfrac{v_1^a v_2^b}{v_3^c}, \quad \Pi_2 = \dfrac{v_4^d}{v_5^e},
\]

where $v_i$ are base variables with dimensions, and $a, b, c, d, e$ are exponents ensuring dimensionlessness.

Using the algorithm:

\begin{enumerate}
	\item \textbf{Transformation Functions:}
	\begin{itemize}
		\item $f(\Phi)$: Permutes the columns to generate $\Pi_2$ and $\Pi_1$.
		\item $g(\Phi)$: Combines $\Pi_1$ and $\Pi_2$ to form $\Pi_3 = \Pi_1 \times \Pi_2$.
	\end{itemize}
	\item \textbf{Vector $\mathbf{v}$:}
	\begin{itemize}
		\item A vector of scaling factors or weights, possibly derived from data or set to one for simplicity.
	\end{itemize}
	\item \textbf{Nonlinear Transformation:}
	\begin{itemize}
		\item $\Phi_{\text{nl}} = \mathbf{v} \otimes \left( f(\Phi) + g(\Phi) \right)$.
		\item Generates candidate functions like $\Pi_1$, $\Pi_2$, $\Pi_3$, and higher-order terms.
	\end{itemize}
	\item \textbf{Model Incorporation:}
	\begin{itemize}
		\item Use $\Phi_{\text{nl}}$ as predictors in the logistic regression model.
	\end{itemize}
\end{enumerate}

\subsection{Advantages of the Algorithm}

\begin{itemize}
	\item \textbf{Systematic Feature Generation:} Provides a methodical way to generate nonlinear features that are dimensionally consistent.
	\item \textbf{Physical Interpretability:} Maintains the physical meaning of variables and their relationships.
	\item \textbf{Enhanced Predictive Power:} Captures complex interactions and nonlinearities, potentially improving model performance.
	\item \textbf{Dimensional Consistency:} Ensures that all generated functions adhere to the principles of dimensional analysis.
\end{itemize}

\subsection{Implications for Equation Discovery}

The algorithm can assist in deriving empirical equations by identifying significant nonlinear combinations of variables that correlate with the target outcome. By focusing on dimensionless groups and their transformations, the derived equations are more likely to represent fundamental physical relationships.

\subsection{Integration with Equivalence Classes}

By generating and analyzing the nonlinear combinations of Pi groups, the algorithm can reveal equivalences between different systems. Systems that share similar transformed Pi groups may belong to the same equivalence class, exhibiting analogous behaviors.

\subsection{Summary}

We have introduced an algorithm that extends the categorical framework by generating nonlinear candidate functions from dimensionless Pi groups. By leveraging tensor products and transformations within the category of dimensionless quantities, the algorithm provides a powerful tool for machine learning models, equation discovery, and the establishment of equivalences between systems. This integration reinforces the versatility of the categorical approach in unifying physical and data-driven modeling.

	
	
	\section{Applications to Machine Learning Models}
	
	\subsection{Categorical Representation of Machine Learning Models}
	
	\begin{definition}[Golden Machine Learning Model]
		A \emph{machine learning model} can be represented as a category $\mathcal{M}$ where:
		\begin{itemize}
			\item Objects are layers or components of the model (e.g., neurons, layers in a neural network).
			\item Morphisms are the functions or mappings between layers (e.g., activation functions, weight matrices).
		\end{itemize}
	\end{definition}
	
	\subsection{Dimensionless Groups in Machine Learning}
	
	\begin{definition}[Dimensionless Hyperparameters]
		A \emph{dimensionless group} in machine learning could be a ratio of hyperparameters or variables that lacks units, such as the ratio of learning rate $\eta$ to batch size $B$, forming a dimensionless quantity $\Pi_{\text{ML}} = \dfrac{\eta}{B}$.
	\end{definition}
	
	\begin{theorem}[Hyperparameter Harmony Theorem]
		Models sharing the same dimensionless hyperparameter groups exhibit similar training dynamics and can be classified into the same equivalence class.
		
		\begin{proof}
			Dimensionless hyperparameter groups capture the relative influence of different training parameters on model behavior. For example, the ratio of learning rate to batch size affects the convergence rate and stability of training.
			
			If two models have the same $\Pi_{\text{ML}}$, they operate under similar conditions in the hyperparameter space, leading to analogous training dynamics. By classifying models based on these dimensionless groups, we can predict their behavior and transfer insights between models within the same equivalence class.
			
			Therefore, models with the same dimensionless hyperparameter groups can be transformed into one another via isometric transformations (scaling of hyperparameters while preserving their ratios), and they exhibit similar behaviors, justifying their classification into the same equivalence class.
		\end{proof}
	\end{theorem}
	
	\subsection{Transfer Learning as a Functor}
	
	\begin{definition}[Transfer Transformation]
		\emph{Transfer learning} can be viewed as a functor $T: \mathcal{M}_1 \rightarrow \mathcal{M}_2$, mapping a pre-trained model $\mathcal{M}_1$ to a new model $\mathcal{M}_2$ for a different but related task.
		
		The functor $T$:
		\begin{itemize}
			\item Maps objects (layers) in $\mathcal{M}_1$ to objects in $\mathcal{M}_2$.
			\item Maps morphisms (functions between layers) in $\mathcal{M}_1$ to morphisms in $\mathcal{M}_2$.
		\end{itemize}
	\end{definition}
	
	\begin{theorem}[Transfer Learning Functor Theorem]
		If the transfer learning functor $T$ preserves the structural and quantitative relationships (i.e., isomorphic and isometric invariances), then the performance on the new task can be predicted based on the original model's performance.
		
		\begin{proof}
			By representing transfer learning as a functor $T$, we formalize the mapping between the pre-trained model $\mathcal{M}_1$ and the new model $\mathcal{M}_2$. If $T$ is:
			\begin{itemize}
				\item \textbf{Isomorphic:} Preserves the architecture and structural relationships between layers, ensuring that the functional form of the model is maintained.
				\item \textbf{Isometric:} Preserves the quantitative relationships, such as weight magnitudes and activation patterns, possibly up to scaling factors.
			\end{itemize}
			
			Under these conditions, the essential features and learned representations in $\mathcal{M}_1$ are retained in $\mathcal{M}_2$. As a result, the performance of $\mathcal{M}_2$ on the new task can be inferred from the performance of $\mathcal{M}_1$, adjusted for differences in task complexity and data distributions.
			
			Therefore, understanding the functorial mapping $T$ allows us to predict and analyze $\mathcal{M}_2$ based on $\mathcal{M}_1$, leveraging the invariances preserved during transfer learning.
		\end{proof}
	\end{theorem}
	
	\section{Buckingham Pi Theorem and Free Object Generators}
	
	\subsection{Buckingham Pi Theorem in the Categorical Framework}
	
	\begin{definition}[Buckingham Pi Phenomenon]
		The \emph{Buckingham Pi theorem} states that any physically meaningful equation involving a certain number $n$ of physical variables can be equivalently rewritten as an equation involving a set of $k = n - r$ dimensionless parameters, where $r$ is the rank of the dimensional matrix formed by the dimensions of the variables.
		
		Formally, if we have variables $v_1, v_2, \dots, v_n$ with dimensions, there exist $k$ dimensionless groups $\Pi_1, \Pi_2, \dots, \Pi_k$ such that:
		\[
		f(v_1, v_2, \dots, v_n) = 0 \quad \iff \quad \phi(\Pi_1, \Pi_2, \dots, \Pi_k) = 0.
		\]
	\end{definition}
	
	\subsection{Dimensionless Groups as Free Objects}
	
	\begin{definition}[Free Object Generator]
		In category theory, a \emph{free object} on an object $X$ in a category $\mathcal{C}$ is an object $F(X)$ together with a morphism $\eta_X: X \rightarrow F(X)$ that satisfies a universal property.
		
		In the context of dimensional analysis, the process of forming dimensionless groups can be viewed as generating free objects in a category of dimensionless quantities.
	\end{definition}
	
	\begin{theorem}[Free Pi Theorem]
		The Buckingham Pi Theorem can be interpreted as constructing a free object in the category of dimensionless quantities, generated by the dimensioned variables subject to dimensional invariance.
		
		\begin{proof}
			Consider the category $\mathcal{C}$ whose objects are dimensioned variables and whose morphisms are dimensionally consistent functions between them. The dimensionless groups $\Pi_i$ are constructed by taking products of powers of the original variables:
			\[
			\Pi_i = \prod_{j=1}^n v_j^{a_{ij}},
			\]
			where the exponents $a_{ij}$ are determined by solving the dimensional homogeneity equations.
			
			This process can be seen as generating free objects in a category $\mathcal{D}$ of dimensionless quantities, where the $\Pi_i$ are the free generators. The mapping from the original variables to the dimensionless groups satisfies a universal property: any dimensionally consistent relationship between the original variables factors uniquely through the dimensionless groups.
			
			Therefore, the Buckingham Pi theorem constructs free objects on the set of dimensioned variables, capturing all possible dimensionless invariants derived from them.
		\end{proof}
	\end{theorem}
	
	\subsection{Application to Drag Force and Reynolds Number}
	
	\begin{definition}[Drag Force Dynamics]
		Consider the problem of determining the drag force $F_D$ on an object moving through a fluid. The variables involved are:
		\begin{itemize}
			\item $F_D$: Drag force ($[M][L][T]^{-2}$).
			\item $\rho$: Fluid density ($[M][L]^{-3}$).
			\item $v$: Velocity of the object relative to the fluid ($[L][T]^{-1}$).
			\item $L$: Characteristic length (e.g., diameter) of the object ($[L]$).
			\item $\mu$: Dynamic viscosity of the fluid ($[M][L]^{-1}[T]^{-1}$).
		\end{itemize}
	\end{definition}
	
	\begin{definition}
		Using the Buckingham Pi theorem, we can express the drag force $F_D$ as a function of the Reynolds number $\operatorname{Re}$:
		\[
		F_D = \rho v^2 L^2 \cdot \phi(\operatorname{Re}),
		\]
		where the Reynolds number is defined as:
		\[
		\operatorname{Re} = \dfrac{\rho v L}{\mu}.
		\]
		
	\end{definition}
	
	\subsection{Buckingham Pi as a Simplification}
	
	In this example, the Buckingham Pi theorem reduces a complex relationship involving five variables to a simpler relationship involving only one dimensionless group (since $\Pi_1$ is expressed in terms of $\Pi_2$). This can be viewed as a special case where the free object generator produces a mapping from the invariants (dimensionless groups) to the dimensioned variables, effectively simplifying the problem.
	
	\begin{proposition}[Simplification via Free Object Generator]
		The Buckingham Pi theorem acts as a free object generator on one object (the dimensionless group), providing a unique mapping from the invariant to the original variables, thereby simplifying the functional relationship.
		
		\begin{proof}
			By generating the dimensionless group $\Pi_2 = \operatorname{Re}^{-1}$, we reduce the dependency of the drag force on multiple variables to a single functional dependency on $\operatorname{Re}$. The free object generator constructs $\Pi_2$ freely from the dimensioned variables while satisfying dimensional homogeneity.
			
			The function $\phi(\operatorname{Re})$ encapsulates all the complex interactions between the original variables within a single argument. This demonstrates how the Buckingham Pi theorem simplifies the problem by creating a free object (dimensionless group) that serves as the sole variable in the functional relationship.
		\end{proof}
	\end{proposition}
	
	\subsection{Implications in the Categorical Framework}
	
	Within our categorical framework, the Buckingham Pi theorem's role as a free object generator highlights how dimensionless groups serve as universal mappings that capture the essence of physical relationships. By interpreting the theorem in this way, we see that:
	
	\begin{itemize}
		\item The dimensionless groups are objects in a category of invariants.
		\item The mapping from dimensioned variables to dimensionless groups is a functorial process that preserves the structure of the relationships.
		\item The dimensionless groups act as free generators that define how invariants are mapped to the dimensioned variables.
	\end{itemize}
	
	This perspective reinforces the power of dimensional analysis within the categorical framework and illustrates how the Buckingham Pi theorem provides a systematic method for simplifying complex physical problems.
	
	\section{Universal Properties in Dimensional Analysis}
	
	\subsection{Universal Objects and Universal Properties}
	
	\begin{definition}[Goldrick's Universal Properties]
		In category theory, an object $U$ in a category $\mathcal{C}$ is said to have a \emph{universal property} if it is initial, terminal, or satisfies a certain universal mapping property that characterizes it uniquely up to unique isomorphism.
		
		\begin{itemize}
			\item An \emph{initial object} $I$ is an object such that for every object $A$ in $\mathcal{C}$, there exists a unique morphism from $I$ to $A$.
			\item A \emph{terminal object} $T$ is an object such that for every object $A$ in $\mathcal{C}$, there exists a unique morphism from $A$ to $T$.
		\end{itemize}
	\end{definition}
	
	\subsection{Application to Dimensionless Quantities}
	
	\begin{theorem}[Dimensionless Terminality Theorem]
		The dimensionless quantity (i.e., the unitless object) can be considered a terminal object in the category of dimensioned quantities.
		
		\begin{proof}
			Let $\mathcal{C}$ be the category of dimensioned quantities, where objects are physical quantities with dimensions, and morphisms are dimension-preserving functions between them.
			
			Consider the dimensionless quantity $\mathbf{1}$ (representing a pure number with no dimensions). For every dimensioned quantity $Q$ in $\mathcal{C}$, there exists a unique morphism (dimensionless scaling) from $Q$ to $\mathbf{1}$ given by:
			\[
			f_Q: Q \rightarrow \mathbf{1}, \quad f_Q(q) = \dfrac{q}{q_0},
			\]
			where $q_0$ is a reference value of the same dimension as $q$, making the ratio dimensionless.
			
			Since for every object $Q$ there is a unique morphism to $\mathbf{1}$, the dimensionless quantity $\mathbf{1}$ serves as a terminal object in $\mathcal{C}$.
		\end{proof}
	\end{theorem}
	
	\subsection{Universal Properties and Dimensional Homogeneity}
	
	\begin{theorem}[Universal Mapping Property of Dimensionless Groups]
		Dimensionless groups satisfy a universal mapping property in the category of physical quantities, acting as mediators through which all dimensionally consistent relationships factor uniquely.
		
		\begin{proof}
			Let $\mathcal{C}$ be the category where objects are sets of dimensioned variables, and morphisms are dimensionally consistent functions.
			
			Given a set of dimensioned variables $\{v_i\}$ and any dimensionally consistent function $f: \{v_i\} \rightarrow \mathbb{R}$, there exists a unique factorization through the dimensionless groups $\{\Pi_j\}$ constructed from $\{v_i\}$ via the Buckingham Pi theorem:
			\[
			f = \phi \circ \psi,
			\]
			where $\psi: \{v_i\} \rightarrow \{\Pi_j\}$ maps variables to dimensionless groups, and $\phi: \{\Pi_j\} \rightarrow \mathbb{R}$ is a function of dimensionless groups.
			
			This factorization is unique due to the universal property of dimensionless groups in capturing all dimensionally invariant information from the original variables. Therefore, dimensionless groups serve as universal objects mediating all dimensionally consistent functions.
		\end{proof}
	\end{theorem}
	
	\subsection{Implications for Physical Laws}
	
	\begin{proposition}[Universality of Physical Laws]
		Physical laws that are expressed in terms of dimensionless groups have a universal character, as they are independent of the specific units used and capture fundamental relationships.
		
		\begin{proof}
			Since dimensionless groups are invariant under changes of units and capture the essence of the relationships between physical quantities, expressing physical laws in terms of dimensionless groups makes them universally applicable.
			
			This universality reflects the fact that the laws depend only on the structure of the relationships, not on arbitrary choices of measurement units. Therefore, when a physical law is formulated using dimensionless groups, it attains a universal status within the framework of dimensional analysis.
		\end{proof}
	\end{proposition}
	
	\subsection{Universal Constructions in Dimensional Analysis}
	
	The use of universal properties in dimensional analysis emphasizes the fundamental role of dimensionless groups and invariants. By viewing dimensionless groups as terminal objects or as objects satisfying universal mapping properties, we can:
	
	\begin{itemize}
		\item Understand the uniqueness and universality of dimensionless relationships in physical systems.
		\item Recognize that any dimensionally consistent function factors through the dimensionless groups, highlighting their central role.
		\item Appreciate how dimensional analysis identifies universal aspects of physical laws, independent of specific units or scales.
	\end{itemize}
	
	\section{Conclusion}
	
	We have developed a categorical framework that formalizes dimensional analysis using display categories, functors, natural transformations, and universal properties. By introducing isometric and isomorphic invariances of dimensionless groups, we can classify physical systems into equivalence classes based on their behaviors. We have explored how linear dependence in dimension vector spaces can lead to overfitting due to dimensional redundancy, drawing parallels with multicollinearity in machine learning. Additionally, we have shown how the Buckingham Pi theorem operates within this framework as a special case involving free object generators, simplifying complex relationships by mapping invariants to dimensioned variables. By incorporating universal objects and properties, we have further highlighted the foundational role of dimensionless groups in capturing the essence of physical relationships. By extending the framework to account for chaos and randomness in dynamical systems, we have demonstrated its versatility and potential for analyzing complex behaviors. This approach unifies different physical domains and enhances our ability to analyze and predict system behaviors across various fields, including machine learning models. The framework provides a foundation for further exploration of categorical structures in complex systems.
	
\end{document}
