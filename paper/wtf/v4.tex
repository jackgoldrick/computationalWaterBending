\documentclass{article}
\usepackage{amsmath, amsthm, amsfonts, amssymb}
\usepackage{tikz-cd}
\usepackage{geometry}
\geometry{margin=1in}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\title{Categorical Framework for Dimensional Analysis and System Classification}
\author{}
\date{}

\begin{document}
	
	\maketitle
	
	\begin{abstract}
		This paper develops a categorical framework to formalize dimensional analysis using display categories, functors, and natural transformations. By introducing isometric and isomorphic invariances of dimensionless groups, we establish a method to classify physical systems into equivalence classes based on their behaviors. This framework unifies different physical domains and provides a systematic approach to analyze and predict system behaviors across various fields, including applications to machine learning models. We also explore the implications of linear dependence in dimension vector spaces on overfitting in modeling and discuss how the Buckingham Pi theorem fits into this framework as a special case involving free object generators.
	\end{abstract}
	
	\tableofcontents
	
	\section{Introduction}
	
	Dimensional analysis is a fundamental tool in physics and engineering, providing insight into the relationships between physical quantities and allowing for the formation of dimensionless groups that characterize system behaviors. In this paper, we extend the traditional approach by applying category theory to dimensional analysis, introducing \emph{display categories}, functors, and natural transformations to create a formal framework for classifying and comparing physical systems. We further explore applications of this framework in machine learning models, discuss how linear dependence in dimension vector spaces relates to overfitting in modeling, and examine how the Buckingham Pi theorem operates within this categorical context.
	
	\section{Preliminaries}
	
	\subsection{Basic Definitions in Category Theory}
	
	\begin{definition}[Category Concepts Carnival]
		A \emph{category} $\mathcal{C}$ consists of:
		\begin{itemize}
			\item A class of \emph{objects} $\operatorname{Ob}(\mathcal{C})$.
			\item For every pair of objects $A, B \in \operatorname{Ob}(\mathcal{C})$, a set of \emph{morphisms} (or arrows) $\operatorname{Hom}_{\mathcal{C}}(A, B)$.
			\item For every triple of objects $A, B, C \in \operatorname{Ob}(\mathcal{C})$, a composition law $\circ: \operatorname{Hom}_{\mathcal{C}}(B, C) \times \operatorname{Hom}_{\mathcal{C}}(A, B) \rightarrow \operatorname{Hom}_{\mathcal{C}}(A, C)$.
			\item For every object $A \in \operatorname{Ob}(\mathcal{C})$, an identity morphism $\operatorname{id}_A \in \operatorname{Hom}_{\mathcal{C}}(A, A)$.
		\end{itemize}
		These must satisfy the associativity and identity axioms.
	\end{definition}
	
	\begin{definition}[Fantastic Functor]
		A \emph{functor} $F: \mathcal{C} \rightarrow \mathcal{D}$ between categories $\mathcal{C}$ and $\mathcal{D}$ is a mapping that:
		\begin{itemize}
			\item Assigns to each object $A \in \operatorname{Ob}(\mathcal{C})$ an object $F(A) \in \operatorname{Ob}(\mathcal{D})$.
			\item Assigns to each morphism $f: A \rightarrow B$ in $\mathcal{C}$ a morphism $F(f): F(A) \rightarrow F(B)$ in $\mathcal{D}$.
		\end{itemize}
		Such that:
		\begin{itemize}
			\item $F(\operatorname{id}_A) = \operatorname{id}_{F(A)}$ for all $A \in \operatorname{Ob}(\mathcal{C})$.
			\item $F(g \circ f) = F(g) \circ F(f)$ for all composable morphisms $f, g$ in $\mathcal{C}$.
		\end{itemize}
	\end{definition}
	
	\begin{definition}[Natural Transformation Treasure]
		Given two functors $F, G: \mathcal{C} \rightarrow \mathcal{D}$, a \emph{natural transformation} $\eta: F \Rightarrow G$ assigns to each object $A \in \operatorname{Ob}(\mathcal{C})$ a morphism $\eta_A: F(A) \rightarrow G(A)$ in $\mathcal{D}$, such that for every morphism $f: A \rightarrow B$ in $\mathcal{C}$, the following diagram commutes:
		\[
		\begin{tikzcd}
			F(A) \arrow[r, "F(f)"] \arrow[d, "\eta_A"'] & F(B) \arrow[d, "\eta_B"] \\
			G(A) \arrow[r, "G(f)"'] & G(B)
		\end{tikzcd}
		\]
	\end{definition}
	
	\subsection{Dimensional Analysis and Dimensionless Groups}
	
	\begin{definition}[Dimension Delight]
		A \emph{dimension} is a fundamental measure of a physical quantity, represented symbolically (e.g., mass $[M]$, length $[L]$, time $[T]$).
		
		A \emph{dimensioned quantity} is a physical variable associated with a combination of dimensions, expressed as $[M]^a[L]^b[T]^c$, where $a, b, c \in \mathbb{R}$.
	\end{definition}
	
	\begin{definition}[Dimensionless Dazzler]
		A \emph{dimensionless group} is a combination of physical variables and constants that results in a quantity without units, i.e., all dimensions cancel out.
	\end{definition}
	
	\subsection{Dimension Vector Spaces}
	
	\begin{definition}[Vector Space Voyage]
		The \emph{dimension vector space} $\mathcal{V}_D$ is a real vector space formed by the exponents of the fundamental dimensions. Each dimensioned quantity corresponds to a vector in $\mathcal{V}_D$.
	\end{definition}
	
	\section{Display Categories and Dimensional Systems}
	
	\subsection{Display Categories}
	
	\begin{definition}[Display Dynamo]
		A \emph{display category} $\mathcal{V}$ over a base category $\mathcal{D}$ is a category where:
		\begin{itemize}
			\item Objects of $\mathcal{V}$ are variables associated with dimensions in $\mathcal{D}$.
			\item Morphisms in $\mathcal{V}$ represent relationships (e.g., equations, transformations) between these variables.
			\item There is a functor $p: \mathcal{V} \rightarrow \mathcal{D}$ called the \emph{display functor}, which maps each variable to its associated dimension.
		\end{itemize}
	\end{definition}
	
	\subsection{Base Category of Dimensions}
	
	Let $\mathcal{D}$ be the base category where:
	\begin{itemize}
		\item $\operatorname{Ob}(\mathcal{D})$ consists of fundamental dimensions $[M], [L], [T], \dots$.
		\item Morphisms in $\mathcal{D}$ represent dimension transformations (e.g., scaling, combination).
	\end{itemize}
	
	\subsection{Variables and Morphisms}
	
	In the display category $\mathcal{V}$:
	\begin{itemize}
		\item Objects are physical variables (e.g., mass $m$, velocity $v$, force $F$) with associated dimensions via the functor $p$.
		\item Morphisms represent physical laws or relationships between variables (e.g., $F = m a$, $v = \dfrac{dx}{dt}$).
	\end{itemize}
	
	\section{Functors and Natural Transformations in Dimensional Systems}
	
	\subsection{Unit Systems as Functors}
	
	Let $\mathcal{U}_{\text{SI}}$ and $\mathcal{U}_{\text{Imperial}}$ be categories representing the SI and Imperial unit systems, respectively.
	
	Define functors:
	\begin{align*}
		F_{\text{SI}} &: \mathcal{D} \rightarrow \mathcal{U}_{\text{SI}}, \\
		F_{\text{Imperial}} &: \mathcal{D} \rightarrow \mathcal{U}_{\text{Imperial}}.
	\end{align*}
	
	These functors map dimensions to units in each system.
	
	\subsection{Natural Transformations as Unit Conversions}
	
	\begin{definition}[Conversion Conjurer]
		A natural transformation $\eta: F_{\text{SI}} \Rightarrow F_{\text{Imperial}}$ represents unit conversions between the SI and Imperial systems.
		
		For each dimension $[D] \in \operatorname{Ob}(\mathcal{D})$, $\eta_{[D]}: F_{\text{SI}}([D]) \rightarrow F_{\text{Imperial}}([D])$ is the conversion factor between units.
	\end{definition}
	
	\subsection{Invariance of Dimensionless Groups}
	
	\begin{theorem}[Invariant Invincibility Theorem]
		Let $\Pi$ be a dimensionless group formed from variables in $\mathcal{V}$ associated with dimensions in $\mathcal{D}$. Then, under the natural transformation $\eta: F_{\text{SI}} \Rightarrow F_{\text{Imperial}}$, $\Pi$ remains invariant.
		
		\begin{proof}
			Since $\Pi$ is dimensionless, it is constructed such that all dimensional units cancel out. Under the natural transformation $\eta$, each variable transforms according to unit conversion factors, but the ratios and products in $\Pi$ ensure that these factors cancel. Therefore, $\Pi$ is invariant under $\eta$.
		\end{proof}
	\end{theorem}
	
	\section{Isometric and Isomorphic Invariances}
	
	\subsection{Isometric Invariance}
	
	\begin{definition}[Isometric Illusion]
		An \emph{isometric transformation} in this context is a mapping between two systems that preserves quantitative relationships, such as ratios or magnitudes of variables.
		
		Formally, consider two systems $S_1$ and $S_2$ with variable sets $\{v_i\}$ and $\{v'_i\}$, respectively. An isometric transformation $\phi: S_1 \rightarrow S_2$ satisfies:
		\[
		\phi(v_i) = k v_i,
		\]
		where $k$ is a constant scaling factor, and the relationships between variables in $S_1$ are preserved in $S_2$.
		
		Two systems are \emph{isometrically invariant} if there exists an isometric transformation between them that preserves these quantitative relationships.
	\end{definition}
	
	\begin{theorem}[Isometric Invariance Preservation]
		If two systems $S_1$ and $S_2$ are related by an isometric transformation $\phi$, then any dimensionless groups formed from variables in $S_1$ are invariant under $\phi$.
		
		\begin{proof}
			Let $\Pi$ be a dimensionless group formed from variables in $S_1$:
			\[
			\Pi = \prod_{i=1}^n v_i^{\alpha_i},
			\]
			where $\alpha_i \in \mathbb{R}$, and the product results in a dimensionless quantity.
			
			Applying the isometric transformation $\phi$:
			\[
			\phi(\Pi) = \prod_{i=1}^n \phi(v_i)^{\alpha_i} = \prod_{i=1}^n (k v_i)^{\alpha_i} = k^{\sum_{i=1}^n \alpha_i} \Pi.
			\]
			
			Since $\Pi$ is dimensionless, the exponents of the dimensions sum to zero, so $\sum_{i=1}^n \alpha_i [D_i] = 0$. Therefore, the scaling factor $k$ raised to the power of zero is one:
			\[
			k^{\sum_{i=1}^n \alpha_i} = k^0 = 1.
			\]
			Thus:
			\[
			\phi(\Pi) = \Pi.
			\]
			Therefore, dimensionless groups are invariant under isometric transformations.
		\end{proof}
	\end{theorem}
	
	\subsection{Isomorphic Invariance}
	
	\begin{definition}[Isomorphism Intrigue]
		An \emph{isomorphism} between two categories $\mathcal{C}$ and $\mathcal{D}$ is a functor $F: \mathcal{C} \rightarrow \mathcal{D}$ that is invertible, i.e., there exists a functor $G: \mathcal{D} \rightarrow \mathcal{C}$ such that $G \circ F = \operatorname{id}_{\mathcal{C}}$ and $F \circ G = \operatorname{id}_{\mathcal{D}}$.
		
		Two systems are \emph{isomorphically invariant} if their categories are isomorphic, preserving the structural relationships between variables and equations.
	\end{definition}
	
	\begin{theorem}[Isomorphic Invariance Preservation]
		If two systems $S_1$ and $S_2$ have categories $\mathcal{C}_1$ and $\mathcal{C}_2$ that are isomorphic via a functor $F: \mathcal{C}_1 \rightarrow \mathcal{C}_2$, then the structural relationships (morphisms) in $S_1$ are preserved in $S_2$.
		
		\begin{proof}
			Since $F$ is an isomorphism, it maps objects and morphisms in $\mathcal{C}_1$ to objects and morphisms in $\mathcal{C}_2$ such that the categorical structure is preserved.
			
			For any objects $A$, $B$ in $\mathcal{C}_1$, and any morphism $f: A \rightarrow B$, $F(f): F(A) \rightarrow F(B)$ in $\mathcal{C}_2$.
			
			Because $G \circ F = \operatorname{id}_{\mathcal{C}_1}$ and $F \circ G = \operatorname{id}_{\mathcal{C}_2}$, $F$ is invertible, ensuring that the structural relationships are fully preserved.
			
			Therefore, the equations and relationships in $S_1$ are mapped to equivalent equations and relationships in $S_2$, preserving the system's structure.
		\end{proof}
	\end{theorem}
	
	\subsection{Examples of Isomorphic Invariance}
	
	\subsubsection{Force-Voltage Analogy}
	
	\begin{definition}[Mechanical-Electrical Analogy]
		The force-voltage analogy is a mapping between mechanical translational systems and electrical circuits, where mechanical quantities are analogous to electrical quantities.
		
		The mappings are as follows:
		\begin{align*}
			\text{Mechanical Quantity} &\quad \text{Electrical Quantity} \\
			\hline
			\text{Force } F(t) &\leftrightarrow \text{Voltage } V(t) \\
			\text{Velocity } v(t) &\leftrightarrow \text{Current } I(t) \\
			\text{Mass } m &\leftrightarrow \text{Inductance } L \\
			\text{Damping } c &\leftrightarrow \text{Resistance } R \\
			\text{Stiffness } k &\leftrightarrow \text{Reciprocal of Capacitance } \dfrac{1}{C}
		\end{align*}
	\end{definition}
	
	\begin{theorem}[Mechanical-Electrical Isomorphism Theorem]
		The equations governing mechanical translational systems and their analogous electrical circuits are structurally identical under the force-voltage analogy, making the systems isomorphically invariant.
		
		\begin{proof}
			Consider the mechanical system described by Newton's second law:
			\[
			F(t) = m \dfrac{d^2 x(t)}{dt^2} + c \dfrac{d x(t)}{dt} + k x(t).
			\]
			
			Under the force-voltage analogy, map mechanical quantities to electrical quantities:
			\begin{align*}
				F(t) &\mapsto V(t), \\
				x(t) &\mapsto q(t), \quad \text{where } q(t) = \int I(t) dt, \text{ the charge}, \\
				\dfrac{d x(t)}{dt} &\mapsto I(t), \\
				\dfrac{d^2 x(t)}{dt^2} &\mapsto \dfrac{d I(t)}{dt}.
			\end{align*}
			
			Substituting the mappings into the mechanical equation:
			\[
			V(t) = L \dfrac{d I(t)}{dt} + R I(t) + \dfrac{1}{C} q(t),
			\]
			which is the standard form of Kirchhoff's voltage law for an RLC circuit.
			
			Since the differential equations governing both systems are structurally identical under the mapping, the mechanical system and the electrical circuit are isomorphic.
			
			The functor $F: \mathcal{C}_{\text{mech}} \rightarrow \mathcal{C}_{\text{elec}}$ defined by these mappings is invertible, as we can define the inverse mappings from electrical quantities back to mechanical quantities.
			
			Therefore, the systems are isomorphically invariant.
		\end{proof}
	\end{theorem}
	
	\subsubsection{Thermal Circuits and Electrical Analogies}
	
	\begin{definition}[Thermal-Electrical Analogy]
		In thermal systems, heat transfer can be analyzed using an analogy to electrical circuits. The mappings are:
		
		\begin{align*}
			\text{Thermal Quantity} &\quad \text{Electrical Quantity} \\
			\hline
			\text{Temperature Difference } \Delta T &\leftrightarrow \text{Voltage Difference } \Delta V \\
			\text{Heat Flow Rate } \dot{Q} &\leftrightarrow \text{Current } I \\
			\text{Thermal Resistance } R_{\text{th}} &\leftrightarrow \text{Electrical Resistance } R \\
			\text{Thermal Capacitance } C_{\text{th}} &\leftrightarrow \text{Electrical Capacitance } C
		\end{align*}
	\end{definition}
	
	\begin{theorem}[Thermal-Electrical Isomorphism Theorem]
		The equations governing thermal systems and their analogous electrical circuits are structurally identical under the thermal-electrical analogy, making the systems isomorphically invariant.
		
		\begin{proof}
			Consider a thermal system where heat flow is governed by:
			\[
			\dot{Q} = \dfrac{\Delta T}{R_{\text{th}}},
			\]
			and the heat stored in the system is:
			\[
			Q = C_{\text{th}} \Delta T.
			\]
			
			In the electrical analogy, these equations correspond to Ohm's law and the charge-voltage relationship:
			\[
			I = \dfrac{\Delta V}{R},
			\]
			\[
			Q = C \Delta V.
			\]
			
			Furthermore, the time-dependent behavior of the thermal system can be described by the differential equation:
			\[
			C_{\text{th}} \dfrac{d (\Delta T)}{dt} + \dfrac{\Delta T}{R_{\text{th}}} = \dot{Q}_{\text{in}},
			\]
			where $\dot{Q}_{\text{in}}$ is the input heat flow rate.
			
			Similarly, the electrical RC circuit is governed by:
			\[
			C \dfrac{d (\Delta V)}{dt} + \dfrac{\Delta V}{R} = I_{\text{in}},
			\]
			where $I_{\text{in}}$ is the input current.
			
			By mapping thermal quantities to electrical quantities as per the analogy, the differential equations governing the thermal system and the electrical circuit are structurally identical.
			
			Therefore, the thermal system and the electrical circuit are isomorphic under the functor defined by the thermal-electrical analogy.
			
		\end{proof}
	\end{theorem}
	
	\subsection{General Conditions for Isomorphic Invariance}
	
	\begin{theorem}[Isomorphic Invariance Criteria]
		Two physical systems can be considered isomorphically invariant if there exists a bijective functor between their categories that preserves the following:
		
		\begin{itemize}
			\item The form of the governing differential equations.
			\item The relationships between variables (morphisms).
			\item The initial and boundary conditions, if applicable.
		\end{itemize}
		
		\begin{proof}
			Let $\mathcal{C}_1$ and $\mathcal{C}_2$ be the categories representing the two physical systems. A functor $F: \mathcal{C}_1 \rightarrow \mathcal{C}_2$ maps objects and morphisms from $\mathcal{C}_1$ to $\mathcal{C}_2$.
			
			If $F$ is bijective and preserves the structure of the equations and relationships, then for every object and morphism in $\mathcal{C}_1$, there is a corresponding object and morphism in $\mathcal{C}_2$ such that the diagrams commute, and vice versa for the inverse functor.
			
			This ensures that the two systems are structurally identical in terms of their mathematical representations, satisfying the conditions for isomorphic invariance.
			
		\end{proof}
	\end{theorem}
	
	\section{Equivalence Classes via Dimensionless Groups}
	
	\subsection{Classification of Systems}
	
	\begin{definition}[Equivalence Ensemble]
		An \emph{equivalence class} of systems is a set of systems that share the same dimensionless groups and exhibit similar behaviors under corresponding conditions.
		
		We denote an equivalence class $\mathcal{E}_\Pi$ for systems sharing a dimensionless group $\Pi$.
	\end{definition}
	
	\subsection{Formation of Equivalence Classes}
	
	\begin{theorem}[Equivalence Enchantment Theorem]
		Systems that are isometrically or isomorphically invariant under transformations preserving their dimensionless groups belong to the same equivalence class $\mathcal{E}_\Pi$.
		
		\begin{proof}
			Let systems $S_1$ and $S_2$ have categories $\mathcal{C}_1$ and $\mathcal{C}_2$, respectively, with associated dimensionless groups $\Pi_1$ and $\Pi_2$.
			
			Suppose there exists:
			\begin{itemize}
				\item An isometric transformation $\phi: S_1 \rightarrow S_2$ preserving quantitative relationships.
				\item An isomorphism $F: \mathcal{C}_1 \rightarrow \mathcal{C}_2$ preserving structural relationships.
			\end{itemize}
			
			Since $\phi$ and $F$ preserve the dimensionless groups (i.e., $\Pi_1 = \Pi_2$), and the systems exhibit similar behaviors under these transformations, they belong to the same equivalence class $\mathcal{E}_\Pi$.
		\end{proof}
	\end{theorem}
	
	\section{Examples}
	
	\subsection{Reynolds Number in Fluid Dynamics}
	
	\begin{definition}[Reynolds Revelation]
		The \emph{Reynolds number} $\operatorname{Re}$ is a dimensionless group defined as:
		\[
		\operatorname{Re} = \dfrac{\rho v L}{\mu},
		\]
		where:
		\begin{itemize}
			\item $\rho$ is the fluid density ($[M][L]^{-3}$).
			\item $v$ is the fluid velocity ($[L][T]^{-1}$).
			\item $L$ is a characteristic length ($[L]$).
			\item $\mu$ is the dynamic viscosity ($[M][L]^{-1}[T]^{-1}$).
		\end{itemize}
	\end{definition}
	
	\begin{theorem}[Flow Familiarity Theorem]
		Fluid systems with the same Reynolds number $\operatorname{Re}$ exhibit similar flow characteristics and belong to the same equivalence class $\mathcal{E}_{\operatorname{Re}}$.
		
		\begin{proof}
			The Reynolds number $\operatorname{Re}$ encapsulates the ratio of inertial forces to viscous forces in a fluid flow. Systems with the same $\operatorname{Re}$ have proportional relationships between these forces, leading to similar flow patterns (e.g., laminar or turbulent flow).
			
			Through an isometric transformation preserving the Reynolds number, variables in one system can be scaled to those in another while maintaining the quantitative relationships. Therefore, these systems exhibit similar behaviors and belong to the same equivalence class $\mathcal{E}_{\operatorname{Re}}$.
		\end{proof}
	\end{theorem}
	
	\subsection{Electrical-Mechanical System Analogy}
	
	\begin{definition}[Analogous Alliance]
		Consider the mechanical system governed by:
		\[
		F(t) = m \ddot{x}(t) + c \dot{x}(t) + k x(t),
		\]
		and the electrical circuit governed by:
		\[
		V(t) = L \ddot{Q}(t) + R \dot{Q}(t) + \dfrac{1}{C} Q(t).
		\]
	\end{definition}
	
	\begin{theorem}[System Symmetry Theorem]
		The mechanical and electrical systems are isomorphically invariant under a functorial mapping that preserves the structural form of their governing equations.
		
		\begin{proof}
			Define a functor $F: \mathcal{C}_{\text{mech}} \rightarrow \mathcal{C}_{\text{elec}}$ such that:
			\begin{align*}
				F(x(t)) &= Q(t), \\
				F(\dot{x}(t)) &= \dot{Q}(t), \\
				F(\ddot{x}(t)) &= \ddot{Q}(t), \\
				F(F(t)) &= V(t), \\
				F(m) &= L, \\
				F(c) &= R, \\
				F(k) &= \dfrac{1}{C}.
			\end{align*}
			
			The morphisms (differential relationships) are preserved under $F$:
			\[
			F\left( m \ddot{x}(t) + c \dot{x}(t) + k x(t) \right) = L \ddot{Q}(t) + R \dot{Q}(t) + \dfrac{1}{C} Q(t).
			\]
			
			Since $F$ is invertible (with inverse mapping electrical quantities back to mechanical ones), and it preserves the structural relationships, the two systems are isomorphic. Therefore, they are isomorphically invariant and can be classified into the same equivalence class based on their dimensionless group analogs.
		\end{proof}
	\end{theorem}
	
	\section{Extension to Dynamical Systems}
	
	\subsection{Differential Equations as Morphisms}
	
	\begin{definition}[Dynamic Dance]
		In dynamical systems, the evolution of variables over time can be represented as morphisms in the display category.
		
		Let $\mathcal{V}$ be a display category where:
		\begin{itemize}
			\item Objects are state variables $x(t)$, $v(t)$, $a(t)$.
			\item Morphisms are differential equations relating these variables, e.g., $v(t) = \dfrac{dx(t)}{dt}$.
		\end{itemize}
	\end{definition}
	
	\subsection{Transducers as Isometric Morphisms}
	
	\begin{theorem}[Transducer Transformation Theorem]
		An ideal transducer can be represented as an isometric morphism in the display category, preserving power between domains.
		
		\begin{proof}
			Consider an electrical-to-mechanical transducer:
			\[
			\text{Electrical power } P_{\text{elec}} = V(t) I(t), \quad \text{Mechanical power } P_{\text{mech}} = F(t) v(t).
			\]
			
			An ideal transducer satisfies $P_{\text{elec}} = P_{\text{mech}}$. The morphism $T: \mathcal{V}_{\text{elec}} \rightarrow \mathcal{V}_{\text{mech}}$ maps electrical variables to mechanical ones while preserving power:
			\begin{align*}
				T(V(t)) &= F(t), \\
				T(I(t)) &= v(t).
			\end{align*}
			
			Since power is preserved, the quantitative relationships are maintained, making $T$ an isometric morphism.
		\end{proof}
	\end{theorem}
	
	\section{Overfitting and Linear Dependence in Dimension Vector Spaces}
	
	\subsection{Linearly Dependent Units and Dimensional Redundancy}
	
	\begin{definition}[Linear Dependence Delight]
		In the dimension vector space $\mathcal{V}_D$, a set of dimension vectors $\{ \mathbf{d}_1, \mathbf{d}_2, \dots, \mathbf{d}_n \}$ is said to be \emph{linearly dependent} if there exist scalars $\alpha_1, \alpha_2, \dots, \alpha_n$, not all zero, such that:
		\[
		\alpha_1 \mathbf{d}_1 + \alpha_2 \mathbf{d}_2 + \dots + \alpha_n \mathbf{d}_n = \mathbf{0}.
		\]
	\end{definition}
	
	\begin{proposition}[Dimension Dependency Proposition]
		If a physical quantity's dimension vector is a linear combination of other dimension vectors, then the corresponding unit is \emph{dimensionally redundant} in modeling.
		
		\begin{proof}
			Let $\mathbf{d}_w$ be the dimension vector of a physical quantity $w$, and suppose it can be expressed as a linear combination of other dimension vectors:
			\[
			\mathbf{d}_w = \sum_{i=1}^{n} \beta_i \mathbf{d}_i,
			\]
			where $\beta_i \in \mathbb{R}$ and $\mathbf{d}_i$ are the dimension vectors of other physical quantities.
			
			This means that the dimensions of $w$ are determined entirely by the dimensions of the $\{ \mathbf{d}_i \}$. In modeling, including $w$ along with all the $\{ \mathbf{d}_i \}$ introduces redundancy because $w$ does not provide additional independent information beyond what is already captured by the $\{ \mathbf{d}_i \}$. Therefore, $w$ is dimensionally redundant in the context of the model.
		\end{proof}
	\end{proposition}
	
	\subsection{Example: Weight, Mass, and Acceleration}
	
	\begin{definition}[Weighty Wonders]
		Consider the relationship:
		\[
		w = m g,
		\]
		where:
		\begin{itemize}
			\item $w$ is the weight (force) of an object.
			\item $m$ is the mass of the object.
			\item $g$ is the acceleration due to gravity.
		\end{itemize}
	\end{definition}
	
	The dimension vectors are:
	\begin{align*}
		\mathbf{d}_w &= [M][L][T]^{-2} = (1,1,-2), \\
		\mathbf{d}_m &= [M] = (1,0,0), \\
		\mathbf{d}_g &= [L][T]^{-2} = (0,1,-2).
	\end{align*}
	
	We observe that:
	\[
	\mathbf{d}_w = \mathbf{d}_m + \mathbf{d}_g.
	\]
	
	This shows that the dimension vector of $w$ is a linear combination (specifically, the sum) of the dimension vectors of $m$ and $g$, indicating linear dependence.
	
	\subsection{Implications for Modeling and Overfitting}
	
	\begin{theorem}[Overfitting Overload Theorem]
		Including linearly dependent units in a model can lead to overfitting due to dimensional redundancy, analogous to multicollinearity in machine learning.
		
		\begin{proof}
			In modeling physical systems, the goal is to capture the essential relationships between independent variables and dependent variables. Including variables whose dimension vectors are linearly dependent introduces redundancy because these variables can be expressed in terms of other variables already present in the model.
			
			This redundancy increases the complexity of the model without providing new independent information. In statistical modeling, such as regression analysis, including linearly dependent (or highly collinear) predictors can inflate variance, make parameter estimates unstable, and reduce the model's ability to generalize to new data—hallmarks of overfitting.
			
			Similarly, in physical models, incorporating dimensionally redundant variables can cause the model to fit the specific dataset too closely, capturing noise rather than underlying physical laws. By analogy with multicollinearity, this overfitting reduces the model's predictive power and interpretability.
			
			Therefore, to prevent overfitting due to dimensional redundancy, it is important to identify and remove or combine linearly dependent units, simplifying the model while retaining its essential predictive capabilities.
		\end{proof}
	\end{theorem}
	
	\subsection{Avoiding Dimensional Overfitting in Models}
	
	\begin{proposition}[Simplification Strategy Proposition]
		To prevent overfitting due to dimensional redundancy, models should be simplified by:
		\begin{itemize}
			\item Identifying and removing linearly dependent units.
			\item Using fundamental variables to represent the system.
			\item Employing dimensionless groups to reduce the number of variables.
		\end{itemize}
		
		\begin{proof}
			\begin{itemize}
				\item \textbf{Identifying and Removing Linearly Dependent Units:} By analyzing the dimension vectors of variables, we can detect linear dependencies. Removing redundant variables eliminates unnecessary complexity.
				
				\item \textbf{Using Fundamental Variables:} Focusing on a minimal set of independent variables ensures that the model captures the essential dynamics without overparameterization.
				
				\item \textbf{Employing Dimensionless Groups:} Dimensionless groups combine multiple variables into single entities that capture the relative effects of different physical quantities. This reduces the dimensionality of the problem and mitigates the risk of overfitting.
			\end{itemize}
			
			By applying these strategies, we simplify the model, enhance its generalizability, and maintain interpretability. This approach aligns with the principles of parsimonious modeling and dimensional analysis.
		\end{proof}
	\end{proposition}
	
	\subsection{Analogies with Machine Learning}
	
	\begin{definition}[Feature Finesse]
		In machine learning, \emph{multicollinearity} refers to the presence of features (variables) that are highly correlated or linearly dependent, which can adversely affect model training and interpretation.
	\end{definition}
	
	\begin{corollary}[Modeling Multicollinearity Corollary]
		The presence of linearly dependent dimension vectors in physical modeling is analogous to multicollinearity in machine learning models.
		
		\begin{proof}
			In both physical modeling and machine learning:
			\begin{itemize}
				\item \textbf{Redundancy:} Linearly dependent variables do not provide additional independent information, leading to redundancy.
				\item \textbf{Overfitting Risk:} Redundancy increases model complexity without enhancing predictive power, increasing the risk of overfitting.
				\item \textbf{Parameter Instability:} In statistical models, multicollinearity can cause large variances in parameter estimates. Similarly, in physical models, redundant variables can obscure the true relationships between variables.
			\end{itemize}
			
			Recognizing this analogy allows us to apply strategies from machine learning to physical modeling, such as variable selection, regularization, and dimensionality reduction, to mitigate overfitting due to redundancy.
		\end{proof}
	\end{corollary}
	
	\section{Applications to Machine Learning Models}
	
	\subsection{Categorical Representation of Machine Learning Models}
	
	\begin{definition}[Model Morphism Magic]
		A \emph{machine learning model} can be represented as a category $\mathcal{M}$ where:
		\begin{itemize}
			\item Objects are layers or components of the model (e.g., neurons, layers in a neural network).
			\item Morphisms are the functions or mappings between layers (e.g., activation functions, weight matrices).
		\end{itemize}
	\end{definition}
	
	\subsection{Dimensionless Groups in Machine Learning}
	
	\begin{definition}[Learning Landscape Luminary]
		A \emph{dimensionless group} in machine learning could be a ratio of hyperparameters or variables that lacks units, such as the ratio of learning rate $\eta$ to batch size $B$, forming a dimensionless quantity $\Pi_{\text{ML}} = \dfrac{\eta}{B}$.
	\end{definition}
	
	\begin{theorem}[Hyperparameter Harmony Theorem]
		Models sharing the same dimensionless hyperparameter groups exhibit similar training dynamics and can be classified into the same equivalence class.
		
		\begin{proof}
			Dimensionless hyperparameter groups capture the relative influence of different training parameters on model behavior. For example, the ratio of learning rate to batch size affects the convergence rate and stability of training.
			
			If two models have the same $\Pi_{\text{ML}}$, they operate under similar conditions in the hyperparameter space, leading to analogous training dynamics. By classifying models based on these dimensionless groups, we can predict their behavior and transfer insights between models within the same equivalence class.
			
			Therefore, models with the same dimensionless hyperparameter groups can be transformed into one another via isometric transformations (scaling of hyperparameters while preserving their ratios), and they exhibit similar behaviors, justifying their classification into the same equivalence class.
		\end{proof}
	\end{theorem}
	
	\subsection{Transfer Learning as a Functor}
	
	\begin{definition}[Transfer Transformation]
		\emph{Transfer learning} can be viewed as a functor $T: \mathcal{M}_1 \rightarrow \mathcal{M}_2$, mapping a pre-trained model $\mathcal{M}_1$ to a new model $\mathcal{M}_2$ for a different but related task.
		
		The functor $T$:
		\begin{itemize}
			\item Maps objects (layers) in $\mathcal{M}_1$ to objects in $\mathcal{M}_2$.
			\item Maps morphisms (functions between layers) in $\mathcal{M}_1$ to morphisms in $\mathcal{M}_2$.
		\end{itemize}
	\end{definition}
	
	\begin{theorem}[Transfer Learning Functoriality Theorem]
		If the transfer learning functor $T$ preserves the structural and quantitative relationships (i.e., isomorphic and isometric invariances), then the performance on the new task can be predicted based on the original model's performance.
		
		\begin{proof}
			By representing transfer learning as a functor $T$, we formalize the mapping between the pre-trained model $\mathcal{M}_1$ and the new model $\mathcal{M}_2$. If $T$ is:
			\begin{itemize}
				\item \textbf{Isomorphic:} Preserves the architecture and structural relationships between layers, ensuring that the functional form of the model is maintained.
				\item \textbf{Isometric:} Preserves the quantitative relationships, such as weight magnitudes and activation patterns, possibly up to scaling factors.
			\end{itemize}
			
			Under these conditions, the essential features and learned representations in $\mathcal{M}_1$ are retained in $\mathcal{M}_2$. As a result, the performance of $\mathcal{M}_2$ on the new task can be inferred from the performance of $\mathcal{M}_1$, adjusted for differences in task complexity and data distributions.
			
			Therefore, understanding the functorial mapping $T$ allows us to predict and analyze $\mathcal{M}_2$ based on $\mathcal{M}_1$, leveraging the invariances preserved during transfer learning.
		\end{proof}
	\end{theorem}
	
	\section{Buckingham Pi Theorem and Free Object Generators}
	
	\subsection{Buckingham Pi Theorem in the Categorical Framework}
	
	\begin{definition}[Buckingham Pi Phenomenon]
		The \emph{Buckingham Pi theorem} states that any physically meaningful equation involving a certain number $n$ of physical variables can be equivalently rewritten as an equation involving a set of $k = n - r$ dimensionless parameters, where $r$ is the rank of the dimensional matrix formed by the dimensions of the variables.
		
		Formally, if we have variables $v_1, v_2, \dots, v_n$ with dimensions, there exist $k$ dimensionless groups $\Pi_1, \Pi_2, \dots, \Pi_k$ such that:
		\[
		f(v_1, v_2, \dots, v_n) = 0 \quad \iff \quad \phi(\Pi_1, \Pi_2, \dots, \Pi_k) = 0.
		\]
	\end{definition}
	
	\subsection{Dimensionless Groups as Free Objects}
	
	\begin{definition}[Free Object Generator]
		In category theory, a \emph{free object} on an object $X$ in a category $\mathcal{C}$ is an object $F(X)$ together with a morphism $\eta_X: X \rightarrow F(X)$ that satisfies a universal property.
		
		In the context of dimensional analysis, the process of forming dimensionless groups can be viewed as generating free objects in a category of dimensionless quantities.
	\end{definition}
	
	\begin{theorem}[Buckingham Pi as Free Object Theorem]
		The Buckingham Pi theorem can be interpreted as constructing a free object in the category of dimensionless quantities, generated by the dimensioned variables subject to dimensional invariance.
		
		\begin{proof}
			Consider the category $\mathcal{C}$ whose objects are dimensioned variables and whose morphisms are dimensionally consistent functions between them. The dimensionless groups $\Pi_i$ are constructed by taking products of powers of the original variables:
			\[
			\Pi_i = \prod_{j=1}^n v_j^{a_{ij}},
			\]
			where the exponents $a_{ij}$ are determined by solving the dimensional homogeneity equations.
			
			This process can be seen as generating free objects in a category $\mathcal{D}$ of dimensionless quantities, where the $\Pi_i$ are the free generators. The mapping from the original variables to the dimensionless groups satisfies a universal property: any dimensionally consistent relationship between the original variables factors uniquely through the dimensionless groups.
			
			Therefore, the Buckingham Pi theorem constructs free objects on the set of dimensioned variables, capturing all possible dimensionless invariants derived from them.
		\end{proof}
	\end{theorem}
	
	\subsection{Application to Drag Force and Reynolds Number}
	
	\begin{definition}[Drag Force Dynamics]
		Consider the problem of determining the drag force $F_D$ on an object moving through a fluid. The variables involved are:
		\begin{itemize}
			\item $F_D$: Drag force ($[M][L][T]^{-2}$).
			\item $\rho$: Fluid density ($[M][L]^{-3}$).
			\item $v$: Velocity of the object relative to the fluid ($[L][T]^{-1}$).
			\item $L$: Characteristic length (e.g., diameter) of the object ($[L]$).
			\item $\mu$: Dynamic viscosity of the fluid ($[M][L]^{-1}[T]^{-1}$).
		\end{itemize}
	\end{definition}
	
	\begin{theorem}[Drag Force Functionality Theorem]
		Using the Buckingham Pi theorem, we can express the drag force $F_D$ as a function of the Reynolds number $\operatorname{Re}$:
		\[
		F_D = \rho v^2 L^2 \cdot \phi(\operatorname{Re}),
		\]
		where the Reynolds number is defined as:
		\[
		\operatorname{Re} = \dfrac{\rho v L}{\mu}.
		\]
		
		\begin{proof}
			We start with the variables $F_D$, $\rho$, $v$, $L$, and $\mu$, which involve $n = 5$ variables and $r = 3$ fundamental dimensions ($[M]$, $[L]$, $[T]$).
			
			According to the Buckingham Pi theorem, the number of dimensionless groups is $k = n - r = 5 - 3 = 2$. We need to construct two dimensionless groups.
			
			We choose repeating variables $\rho$, $v$, and $L$ because they collectively include all fundamental dimensions and are dimensionally independent.
			
			We express the dimensionless groups as:
			\[
			\Pi_1 = F_D \cdot \rho^a v^b L^c, \\
			\Pi_2 = \mu \cdot \rho^d v^e L^f.
			\]
			
			Solving for the exponents to ensure dimensional homogeneity:
			
			For $\Pi_1$:
			\[
			[F_D][\rho]^a [v]^b [L]^c = [M]^0 [L]^0 [T]^0.
			\]
			
			Substituting dimensions:
			\[
			[M][L][T]^{-2} \cdot [M]^{a}[L]^{-3a} \cdot [L]^{b}[T]^{-b} \cdot [L]^c = [M]^0 [L]^0 [T]^0.
			\]
			
			Collecting exponents:
			\[
			[M]^{1 + a} [L]^{1 - 3a + b + c} [T]^{-2 - b} = [M]^0 [L]^0 [T]^0.
			\]
			
			Setting exponents to zero:
			\begin{align*}
				1 + a &= 0 \implies a = -1, \\
				1 - 3a + b + c &= 0 \implies 1 - 3(-1) + b + c = 0 \implies b + c = -4, \\
				-2 - b &= 0 \implies b = -2.
			\end{align*}
			
			Thus, $b = -2$, and $c = -4 - b = -4 - (-2) = -2$.
			
			Therefore:
			\[
			\Pi_1 = F_D \cdot \rho^{-1} v^{-2} L^{-2} = \dfrac{F_D}{\rho v^2 L^2}.
			\]
			
			Similarly for $\Pi_2$:
			\[
			[\mu][\rho]^d [v]^e [L]^f = [M]^0 [L]^0 [T]^0.
			\]
			
			Substituting dimensions:
			\[
			[M][L]^{-1}[T]^{-1} \cdot [M]^{d}[L]^{-3d} \cdot [L]^{e}[T]^{-e} \cdot [L]^f = [M]^0 [L]^0 [T]^0.
			\]
			
			Collecting exponents:
			\[
			[M]^{1 + d} [L]^{-1 - 3d + e + f} [T]^{-1 - e} = [M]^0 [L]^0 [T]^0.
			\]
			
			Setting exponents to zero:
			\begin{align*}
				1 + d &= 0 \implies d = -1, \\
				-1 - 3d + e + f &= 0 \implies -1 - 3(-1) + e + f = 0 \implies e + f = -2, \\
				-1 - e &= 0 \implies e = -1.
			\end{align*}
			
			Thus, $e = -1$, and $f = -2 - e = -2 - (-1) = -1$.
			
			Therefore:
			\[
			\Pi_2 = \mu \cdot \rho^{-1} v^{-1} L^{-1} = \dfrac{\mu}{\rho v L} = \operatorname{Re}^{-1}.
			\]
			
			Hence, the two dimensionless groups are:
			\[
			\Pi_1 = \dfrac{F_D}{\rho v^2 L^2}, \quad \Pi_2 = \dfrac{\mu}{\rho v L} = \operatorname{Re}^{-1}.
			\]
			
			Thus, the relationship between the drag force and the Reynolds number is:
			\[
			\Pi_1 = \phi(\Pi_2) \implies \dfrac{F_D}{\rho v^2 L^2} = \phi\left( \dfrac{\mu}{\rho v L} \right).
			\]
			
			Rewriting:
			\[
			F_D = \rho v^2 L^2 \cdot \phi\left( \dfrac{\rho v L}{\mu} \right) = \rho v^2 L^2 \cdot \phi(\operatorname{Re}).
			\]
			
			This demonstrates that the drag force is a function of the Reynolds number, with $\rho v^2 L^2$ providing the scaling factor, and $\phi(\operatorname{Re})$ capturing the dependency on the Reynolds number.
			
		\end{proof}
	\end{theorem}
	
	\subsection{Buckingham Pi as a Simplification}
	
	In this example, the Buckingham Pi theorem reduces a complex relationship involving five variables to a simpler relationship involving only one dimensionless group (since $\Pi_1$ is expressed in terms of $\Pi_2$). This can be viewed as a special case where the free object generator produces a mapping from the invariants (dimensionless groups) to the dimensioned variables, effectively simplifying the problem.
	
	\begin{proposition}[Simplification via Free Object Generator]
		The Buckingham Pi theorem acts as a free object generator on one object (the dimensionless group), providing a unique mapping from the invariant to the original variables, thereby simplifying the functional relationship.
		
		\begin{proof}
			By generating the dimensionless group $\Pi_2 = \operatorname{Re}^{-1}$, we reduce the dependency of the drag force on multiple variables to a single functional dependency on $\operatorname{Re}$. The free object generator constructs $\Pi_2$ freely from the dimensioned variables while satisfying dimensional homogeneity.
			
			The function $\phi(\operatorname{Re})$ encapsulates all the complex interactions between the original variables within a single argument. This demonstrates how the Buckingham Pi theorem simplifies the problem by creating a free object (dimensionless group) that serves as the sole variable in the functional relationship.
		\end{proof}
	\end{proposition}
	
	\subsection{Implications in the Categorical Framework}
	
	Within our categorical framework, the Buckingham Pi theorem's role as a free object generator highlights how dimensionless groups serve as universal mappings that capture the essence of physical relationships. By interpreting the theorem in this way, we see that:
	
	\begin{itemize}
		\item The dimensionless groups are objects in a category of invariants.
		\item The mapping from dimensioned variables to dimensionless groups is a functorial process that preserves the structure of the relationships.
		\item The dimensionless groups act as free generators that define how invariants are mapped to the dimensioned variables.
	\end{itemize}
	
	This perspective reinforces the power of dimensional analysis within the categorical framework and illustrates how the Buckingham Pi theorem provides a systematic method for simplifying complex physical problems.
	
	\section{Conclusion}
	
	We have developed a categorical framework that formalizes dimensional analysis using display categories, functors, and natural transformations. By introducing isometric and isomorphic invariances of dimensionless groups, we can classify physical systems into equivalence classes based on their behaviors. We have explored how linear dependence in dimension vector spaces can lead to overfitting due to dimensional redundancy, drawing parallels with multicollinearity in machine learning. Additionally, we have shown how the Buckingham Pi theorem operates within this framework as a special case involving free object generators, simplifying complex relationships by mapping invariants to dimensioned variables. This approach unifies different physical domains and enhances our ability to analyze and predict system behaviors across various fields, including machine learning models. The framework provides a foundation for further exploration of categorical structures in complex systems.
	
\end{document}
