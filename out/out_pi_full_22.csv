Trial,Model,Train,Test
0,RMSprop,0.8284313725490197,0.8653846153846154
0,Adam,0.8480392156862745,0.8653846153846154
0,AdamW,0.8578431372549019,0.8846153846153846
0,Adagrad,0.8480392156862745,0.9038461538461539
0,Adadelta,0.8480392156862745,0.9038461538461539
0,SGD,0.8431372549019608,0.9038461538461539
0,Nadam,0.8578431372549019,0.9230769230769231
0,Adafactor,0.8676470588235294,0.9230769230769231
0,Adamax,0.8872549019607843,0.9230769230769231
0,LossScaleOptimizer(Adam),0.8970588235294118,0.9230769230769231
1,RMSprop,0.8872549019607843,0.9230769230769231
1,Adam,0.9068627450980392,0.9038461538461539
1,AdamW,0.9215686274509803,0.9230769230769231
1,Adagrad,0.9117647058823529,0.9230769230769231
1,Adadelta,0.9117647058823529,0.9230769230769231
1,SGD,0.9117647058823529,0.9230769230769231
1,Nadam,0.9117647058823529,0.9038461538461539
1,Adafactor,0.9362745098039216,0.8846153846153846
1,Adamax,0.9362745098039216,0.8846153846153846
1,LossScaleOptimizer(Adam),0.9509803921568627,0.8461538461538461
2,RMSprop,0.9558823529411765,0.8653846153846154
2,Adam,0.9656862745098039,0.8461538461538461
2,AdamW,0.9656862745098039,0.8846153846153846
2,Adagrad,0.9705882352941176,0.8846153846153846
2,Adadelta,0.9705882352941176,0.8846153846153846
2,SGD,0.9754901960784313,0.8461538461538461
2,Nadam,0.9754901960784313,0.8461538461538461
2,Adafactor,0.9803921568627451,0.9038461538461539
2,Adamax,0.9803921568627451,0.8846153846153846
2,LossScaleOptimizer(Adam),0.9803921568627451,0.8846153846153846
3,RMSprop,0.9803921568627451,0.8461538461538461
3,Adam,0.9852941176470589,0.8846153846153846
3,AdamW,0.9803921568627451,0.9230769230769231
3,Adagrad,0.9901960784313726,0.9038461538461539
3,Adadelta,0.9901960784313726,0.9038461538461539
3,SGD,0.9901960784313726,0.8461538461538461
3,Nadam,0.9950980392156863,0.8846153846153846
3,Adafactor,1.0,0.8653846153846154
3,Adamax,1.0,0.8846153846153846
3,LossScaleOptimizer(Adam),0.9901960784313726,0.8653846153846154
4,RMSprop,0.9852941176470589,0.8846153846153846
4,Adam,0.9950980392156863,0.9038461538461539
4,AdamW,1.0,0.8846153846153846
4,Adagrad,1.0,0.8846153846153846
4,Adadelta,1.0,0.8846153846153846
4,SGD,0.9950980392156863,0.9038461538461539
4,Nadam,0.9901960784313726,0.8653846153846154
4,Adafactor,1.0,0.9038461538461539
4,Adamax,1.0,0.9038461538461539
4,LossScaleOptimizer(Adam),1.0,0.8846153846153846
