Trial,Model,Train,Test
0,RMSprop,0.8382352941176471,0.8461538461538461
0,Adam,0.8774509803921569,0.8846153846153846
0,AdamW,0.8823529411764706,0.9230769230769231
0,Adagrad,0.8921568627450981,0.9230769230769231
0,Adadelta,0.8921568627450981,0.9230769230769231
0,SGD,0.8970588235294118,0.9230769230769231
0,Nadam,0.9068627450980392,0.8846153846153846
0,Adafactor,0.9166666666666666,0.8653846153846154
0,Adamax,0.9117647058823529,0.8653846153846154
0,LossScaleOptimizer(Adam),0.9313725490196079,0.9038461538461539
1,RMSprop,0.9509803921568627,0.9038461538461539
1,Adam,0.9607843137254902,0.8461538461538461
1,AdamW,0.9656862745098039,0.9038461538461539
1,Adagrad,0.9656862745098039,0.9038461538461539
1,Adadelta,0.9656862745098039,0.9038461538461539
1,SGD,0.9705882352941176,0.9038461538461539
1,Nadam,0.9705882352941176,0.9230769230769231
1,Adafactor,0.9754901960784313,0.9230769230769231
1,Adamax,0.9803921568627451,0.9230769230769231
1,LossScaleOptimizer(Adam),0.9656862745098039,0.9230769230769231
2,RMSprop,0.9754901960784313,0.9230769230769231
2,Adam,0.9754901960784313,0.9038461538461539
2,AdamW,0.9852941176470589,0.9230769230769231
2,Adagrad,0.9901960784313726,0.9423076923076923
2,Adadelta,0.9901960784313726,0.9423076923076923
2,SGD,0.9852941176470589,0.9423076923076923
2,Nadam,0.9950980392156863,0.9423076923076923
2,Adafactor,0.9901960784313726,0.9230769230769231
2,Adamax,0.9950980392156863,0.9230769230769231
2,LossScaleOptimizer(Adam),0.9950980392156863,0.9038461538461539
3,RMSprop,0.9852941176470589,0.9230769230769231
3,Adam,0.9950980392156863,0.9038461538461539
3,AdamW,0.9950980392156863,0.9038461538461539
3,Adagrad,0.9950980392156863,0.9038461538461539
3,Adadelta,0.9950980392156863,0.9038461538461539
3,SGD,0.9950980392156863,0.9038461538461539
3,Nadam,1.0,0.9230769230769231
3,Adafactor,1.0,0.9038461538461539
3,Adamax,1.0,0.9230769230769231
3,LossScaleOptimizer(Adam),1.0,0.9038461538461539
4,RMSprop,0.9950980392156863,0.9230769230769231
4,Adam,1.0,0.8846153846153846
4,AdamW,1.0,0.8846153846153846
4,Adagrad,1.0,0.8846153846153846
4,Adadelta,1.0,0.8846153846153846
4,SGD,1.0,0.8846153846153846
4,Nadam,1.0,0.8846153846153846
4,Adafactor,1.0,0.8846153846153846
4,Adamax,1.0,0.8846153846153846
4,LossScaleOptimizer(Adam),1.0,0.8846153846153846
